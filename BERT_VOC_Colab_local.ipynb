{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "d2b3fe256b094e82a87b624b50b7af86",
        "deepnote_cell_type": "markdown",
        "id": "_u716cCIZIqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT VOC (Colab local)\n",
        "#### v. 20230821"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "acbdd5e51fa346b2b141d7dcf4ba0274",
        "deepnote_cell_type": "markdown",
        "id": "JRkT4Q-yZIqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages to avoid import error `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\n",
        "\n",
        "!pip install -U accelerate\n",
        "!pip install transformers -U\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117      # install PyTorch\n",
        "\n",
        "import accelerate\n",
        "import transformers\n",
        "\n",
        "transformers.__version__, accelerate.__version__"
      ],
      "metadata": {
        "id": "I7P3DUOpgV7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU can be detected\n",
        "# tensorflow-gpu has been removed. tensorflow package supports GPU accelerated operations via Nvidia CUDA.\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()              # '/device:GPU:0' means GPU is enabled\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "8eWAtNCmrzso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# use my own GPU to train; move tensor to my GPU\n",
        "if torch.cuda.is_available():\n",
        "   dev = \"cuda:0\"\n",
        "else:\n",
        "    dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print(device)\n",
        "t1 = torch.zeros(4,3)\n",
        "print(t1)\n",
        "t1 = t1.to(device)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "1KyaineWiqgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# device_lib.list_local_devices()\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "C8bL0YsEblkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the same device is used for tensor allocation during all operations\n",
        "\n",
        "a = t1.get_device()                    # returns the index of the GPU on which the tensor resides\n",
        "b = torch.tensor(t1.shape).to(dev)     # use this index to direct placement for new tensors\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "TJ9368sBG8B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check running environment info regarding Cuda and devices\n",
        "\n",
        "import sys\n",
        "print('__Python VERSION:', sys.version)\n",
        "print('__pyTorch VERSION:', torch.__version__)\n",
        "print('__CUDA VERSION', )\n",
        "\n",
        "from subprocess import call\n",
        "# call([\"nvcc\", \"--version\"]) does not work\n",
        "! nvcc --version\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "print('__Devices')\n",
        "\n",
        "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
        "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
        "print ('Available devices ', torch.cuda.device_count())\n",
        "print ('Current cuda device ', torch.cuda.current_device())"
      ],
      "metadata": {
        "id": "Su8FJpuIKbGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and check device information of my graphics driver\n",
        "\n",
        "!pip install pycuda\n",
        "import pycuda.driver as cuda\n",
        "cuda.init()\n",
        "\n",
        "# Get Id of default device\n",
        "torch.cuda.current_device()\n",
        "# 0\n",
        "cuda.Device(0).name()         # '0' is the id of my GPU"
      ],
      "metadata": {
        "id": "kqdH81CpKa9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo            # check memory resources available"
      ],
      "metadata": {
        "id": "Nf6uQarosHGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCmAhc2i0JDh"
      },
      "outputs": [],
      "source": [
        "# install wandb for tracking data on dashboard\n",
        "!pip install datasets wandb evaluate -qU\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGvsX_9j0JDj"
      },
      "outputs": [],
      "source": [
        "# the run_glue.py script requires transformers dev\n",
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of5C4XID0JDk"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# log in to have data synced to account\n",
        "wandb.login()\n",
        "\n",
        "# log every trained model\n",
        "%env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# filter training data to desired dates (after 2022.2.22)\n",
        "df = pd.read_csv('/test.csv', index_col=0).drop_duplicates()\n",
        "\n",
        "# filter training data to desired dates\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "df = df[df.Date.apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date() > datetime(2022,2,21).date())]\n",
        "\n",
        "# Consider reducing data to cut training time for quick feature testing\n",
        "# df22 = df22.sample(frac=0.01, random_state=5)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9f955299a3e54a1aaebfc738a20d1320",
        "source_hash": "76f0006d",
        "execution_start": 1674080120705,
        "execution_millis": 808,
        "is_output_hidden": false,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "k6xcfS07ZIqd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Title + Content concatenator\n",
        "from timeit import default_timer as timer\n",
        "import re\n",
        "\n",
        "def data_concat(df22, R_known=True):\n",
        "\n",
        "    # Split the input dataframe into Text (Title + Contents) and Classes dataframes\n",
        "    # input must have 3 columns of string entries (Title, Contents, and Classes)\n",
        "\n",
        "    # check if every row entry of each column is string type (some are NaN, so no)\n",
        "    # print(df22.applymap(lambda x : type(x).__name__).eq({'Title': 'str', 'Content': 'str', 'Class':'str'}))\n",
        "\n",
        "    # convert NaN to empty strings (NaN -> str)\n",
        "        # df22.apply(str) converts all columns to str, as well\n",
        "    df22 = df22.replace(float('nan'), '', regex=True)\n",
        "\n",
        "    # concatenate strings of title & content with a \" \" in between (1 body of text)\n",
        "    df22['Text'] = df22['Title'] + \" \" + df22['Content']      # slicing DataFrame via .iloc[:,0] makes it a Series\n",
        "    df22 = df22.loc[: , ['Text', 'Class']]    # so initialize it as a DataFrame. pd.DataFrame(some_Series) works\n",
        "\n",
        "    if R_known == True:\n",
        "    # R, r, YR = 1;     N, n, YN = 0\n",
        "        R_cases = re.compile('R|YR', re.IGNORECASE)\n",
        "        N_cases = re.compile('N|YN', re.IGNORECASE)\n",
        "        df22['Class'] = df22['Class'].replace(to_replace=R_cases, value=1)\n",
        "        df22['Class'] = df22['Class'].replace(to_replace=N_cases, value=0)\n",
        "    else:\n",
        "        # R_known == False; prepping not yet classified data\n",
        "        Y_N_cases = re.compile('Y|N', re.IGNORECASE)\n",
        "        df22['Class'] = df22['Class'].replace(to_replace=Y_N_cases, value=0)     # all N's for simplicity\n",
        "\n",
        "    df22['Class'] = df22['Class'].astype('int32')\n",
        "\n",
        "\n",
        "    return df22\n"
      ],
      "metadata": {
        "id": "I94k-OsHcdmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine title & content as text22, clean the text, then combine it with labels to a single df\n",
        "df = data_concat(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Nh1gY_I2c-aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ddbfd30c829a40c9af60fd8fc4ad8bb3",
        "source_hash": "fda411fd",
        "execution_start": 1674080121523,
        "execution_millis": 6,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "kJtMeTRwZIqe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# reinstalling packages to get around errors\n",
        "!pip uninstall tokenizers, transformers\n",
        "!pip install transformers==4.27.4 -U\n",
        "!pip install diffusers==0.12.1\n",
        "import transformers"
      ],
      "metadata": {
        "id": "S451mbTnfl8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note 20230821:\n",
        "\n",
        "# Below error kept popping up when trying to run 'from transformers import TrainingArguments, Trainer' and 'from transformers import BertTokenizer, BertForSequenceClassification'\n",
        "\"\"\"\n",
        "RuntimeError: Failed to import transformers.training_args because of the following error (look up to see its traceback):\n",
        "cannot import name 'is_torch_npu_available' from 'transformers.utils' (/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py) site:stackoverflow.com\n",
        "\"\"\"\n",
        "# Temporary workaround was to change BertTokenizer into transformers.BertTokenizer and BertForSequenceClassification to transformers.BertForSequenceClassification"
      ],
      "metadata": {
        "id": "069l_9XZhsBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "#from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "#from transformers import BertTokenizer, BertForSequenceClassification\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d968ff4c82ea4fe89fdeecd8ad261bda",
        "source_hash": "65934339",
        "execution_start": 1674080121543,
        "execution_millis": 5340,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "jk_eN8Q0ZIqe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "506970be01814296ad84c7c9f3312165",
        "source_hash": "d991cab6",
        "execution_start": 1674080126876,
        "execution_millis": 88,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "FYxeRDLYZIqf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.to( torch.device('cuda') )     # need NVIDIA driver for 'cuda'; currently have AMD on work laptop\n",
        "# model = model.to('cpu')         # train on CPU\n",
        "\n",
        "model = model.to('cuda')          # or  model.cuda()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "abaddecf0f7a4867b3088265ded4cec5",
        "source_hash": "ff8dd7cb",
        "execution_start": 1674080126980,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "65yDwWirZIqf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [\"This is possibly the worst battery I have ever seen on a mobile device\",\n",
        "            \"How is my device running so smoothly?\"]\n",
        "tokenizer(test_data, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "cbadffae0dd44bbbb994e70f20146772",
        "source_hash": "6c516043",
        "execution_start": 1674080126981,
        "execution_millis": 100,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "-z6XRhJgZIqg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df[\"Text\"])\n",
        "y = list(df[\"Class\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "af668836fd5341ac9016a845ebe79057",
        "source_hash": "25d321c9",
        "execution_start": 1674080127028,
        "execution_millis": 27370,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "o-G23j4EZIqg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized.keys()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "0ddc2b86e99d47f49d560a7a4a7427a9",
        "source_hash": "882ded45",
        "execution_start": 1674080154402,
        "execution_millis": 14,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "O2IkScN2ZIqh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tokenized['attention_mask'][0])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "31306b38d6424983b8ec35e35b89d5d5",
        "source_hash": "c5b8c3f4",
        "execution_start": 1674080169475,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "yn6O2T8lZIqh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train),len(X_val)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "c20d101dd6e84dff850d5446d87227b5",
        "source_hash": "1851768b",
        "execution_start": 1674080189480,
        "execution_millis": 0,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "WPVhi1tNZIqi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch dataset\n",
        "class VOC_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "785f8f506f724850be7cdd073ff8bfd4",
        "source_hash": "3b060da6",
        "execution_start": 1674080232215,
        "execution_millis": 12,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "OC-jBK8SZIqi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOC_Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = VOC_Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9b6f589cb6274e459cf4b21ca9416ac7",
        "source_hash": "78f426a3",
        "execution_start": 1674080252981,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "0J6cyoT6ZIqi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "e74bd73ccb5e49869e5db0dc8d5da4db",
        "source_hash": "a1b8da62",
        "execution_start": 1674080260113,
        "execution_millis": 47,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "WT0-A0GyZIqj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(m):\n",
        "    print(type(m))\n",
        "    pred, labels = m\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d89ebde51e854f5c9bfb45c57a0b8eb2",
        "source_hash": "2986a0e5",
        "execution_start": 1674080319332,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "ItJjuFt_ZIqj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Trainer\n",
        "args = transformers.TrainingArguments(\n",
        "    report_to = 'wandb',                      # enable logging to W&B\n",
        "    output_dir=\"output\",                      # output directory\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8\n",
        "    # overwrite_output_dir = True,\n",
        "    # evaluation_strategy = 'steps',          # check evaluation metrics at each epoch\n",
        "    # learning_rate = 5e-5,                   # we can customize learning rate\n",
        "    # max_steps = 30000,\n",
        "    # logging_steps = 100,                    # log every 100 steps\n",
        "    # eval_steps = 5000,                      # perform evaluation every 5000 steps\n",
        "    # save_steps = 10000,\n",
        "    # load_best_model_at_end = True,\n",
        "    # metric_for_best_model = 'accuracy',\n",
        "    # run_name = 'custom_training'            # name of the W&B run\n",
        "\n",
        ")\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,                 # for padding batched data\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "f95f543b3daa425ebecc01270b25bf91",
        "source_hash": "223c3ba0",
        "execution_start": 1674080330040,
        "execution_millis": 145,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "CFYxNIctZIqj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# clear cache before training\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tsJMU2XDVPjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8185c9ee39774fcba9200e83819fce3f",
        "source_hash": "c4a351e7",
        "execution_start": 1674080563381,
        "execution_millis": 17834,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "8NO7NW3bZIqk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "97a062b8225e4125971486d915e3ac86",
        "deepnote_cell_type": "code",
        "id": "4L3oPcUvZIqk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "2920442657d045288b468403b8e7ce45",
        "deepnote_cell_type": "code",
        "id": "ee-3alVdZIqk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Super charging is working very well.\"\n",
        "# text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "print(outputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)    # also gelu(), silu()\n",
        "print(predictions)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "b95d7749d3074a20bdfa3cdc432b149e",
        "deepnote_cell_type": "code",
        "id": "Ndgwa_feZIql"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('BertPractice')"
      ],
      "metadata": {
        "id": "ehJCv_jKWoge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = transformers.BertForSequenceClassification.from_pretrained('BertPractice')\n",
        "model_2.to('cuda')"
      ],
      "metadata": {
        "id": "9af__siKWrvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Super charging is working very well.\"\n",
        "text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model_2(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "53e74eee144d445da85927276d7daff3",
        "deepnote_cell_type": "code",
        "id": "Nf4WU--hZIql"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to make predictions on daily data\n",
        "\n",
        "def pred_day(voctoday):\n",
        "  voclist = list(voctoday['Text'])\n",
        "  predlist = []\n",
        "\n",
        "  for i in range(len(voclist)):\n",
        "    inputs = tokenizer(voclist[i], padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "    outputs = model_2(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predictions = predictions.cpu().detach().numpy()\n",
        "    predlist.append(predictions)\n",
        "\n",
        "  organizedzip = zip([x[:50] for x in voclist],\n",
        "                    predlist,\n",
        "                    voctoday['Class'])\n",
        "\n",
        "  # results as voc text, predictions, and actual value\n",
        "  vocresult = pd.DataFrame(list(organizedzip), columns=['Text','Prediction','Actual'])\n",
        "\n",
        "  return vocresult\n"
      ],
      "metadata": {
        "id": "MC4gHsQTbo_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test VOC for 8/14 (Mon) - 8/21 (Mon) using model trained on ~8/11 (Fri) data\n",
        "\n",
        "voc814 = pd.read_csv('/814testraw.csv', index_col=0, delimiter=\",\").drop_duplicates()     # use delimiter ',' for original .csv file created from my test file generator\n",
        "voc814 = data_concat(voc814.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc815 = pd.read_csv('/815testraw.csv', index_col=0, delimiter=\",\").drop_duplicates()\n",
        "voc815 = data_concat(voc815.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc816 = pd.read_csv('/816testraw.csv', index_col=0, delimiter=\",\").drop_duplicates()\n",
        "voc816 = data_concat(voc816.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc817 = pd.read_csv('/817testraw.csv', index_col=0, delimiter=\",\").drop_duplicates()\n",
        "voc817 = data_concat(voc817.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc818 = pd.read_csv('/818testraw.csv', index_col=0, delimiter=\",\").drop_duplicates()\n",
        "voc818 = data_concat(voc818.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc821 = pd.read_csv('/821testraw.csv', index_col=0, delimiter=\",\").drop_duplicates()\n",
        "voc821 = data_concat(voc821.loc[: , 'Title':'Class'])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "501fe0946abe4e6398eb6a364a652e3c",
        "source_hash": "b623e53d",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "HOzIXC_iZIqm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult814 = pred_day(voc814)\n",
        "vocresult814"
      ],
      "metadata": {
        "id": "tAz2XQrhZn8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult815 = pred_day(voc815)\n",
        "vocresult815"
      ],
      "metadata": {
        "id": "gZ8b16cyZn2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult816 = pred_day(voc816)\n",
        "vocresult816"
      ],
      "metadata": {
        "id": "MpqBxcdGm9g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult817 = pred_day(voc817)\n",
        "vocresult817"
      ],
      "metadata": {
        "id": "bxUDDeDOulLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult818 = pred_day(voc818)\n",
        "vocresult818"
      ],
      "metadata": {
        "id": "KqkeehXTulGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult821 = pred_day(voc821)\n",
        "vocresult821"
      ],
      "metadata": {
        "id": "UzHiwc4nuk_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e5caba9f-cd36-4d50-aaa3-2cf59957a2f4' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "llB-FWxEZIqn"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {},
    "orig_nbformat": 2,
    "deepnote_notebook_id": "99baf882d48d4fa4b40b67d8bd9057bf",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}