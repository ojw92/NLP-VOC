{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojw92/NLP-for-Text-Classification/blob/main/BERT_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "d2b3fe256b094e82a87b624b50b7af86",
        "deepnote_cell_type": "markdown",
        "id": "_u716cCIZIqP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8M_IjgNzPa9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing (not needed for BERT)\n",
        "\n",
        "# preprocessor.py\n",
        "\n",
        "# Preprocessing steps for RNN & CNN\n",
        "\n",
        "# Model for S22 VOC only, but with added preprocessing steps\n",
        "\n",
        "# https://www.geeksforgeeks.org/python-call-function-from-another-file/\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')    # for lemmatization function; don't need this line if package installed\n",
        "nltk.download('omw-1.4')    # for lemmatization function; don't need this line if package installed\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer     # based on The Porter Stemming Algorithm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91\n",
        "\n",
        "# 0 - split & prepare data for preprocessing                              <- add a preliminary stopword removal step (RNN & CNN)?\n",
        "# 0.5 - remove duplicate data\n",
        "# 1 - remove hyperlinks, emails & pricetags\n",
        "# 2 - remove emoji\n",
        "# 3 - remove punctuations\n",
        "# 4 - apply lower case\n",
        "\n",
        "# ===== use min-df to find low-frequency words =====\n",
        "\n",
        "# 5 - fix misspellings                                                    <- (need to implement!)\n",
        "# 6 - replace words with generic nouns                                    <- (need to implement!)\n",
        "# 7 - remove stopwords       # better to replace then remove?             <- final stopword clean-up step (separate list for RNN & CNN)\n",
        "# 8 - lemmatize\n",
        "# (8.5 - stemming)\n",
        "\n",
        "# 9 - tokenization & padding\n",
        "\n",
        "# ============================================================================================================= 0                 <- add a preliminary stopword removal step\n",
        "\n",
        "def data_split(df22, R_known=True):\n",
        "\n",
        "    # Split the input dataframe into Text (Title + Contents) and Classes dataframes\n",
        "    # input must have 3 columns of string entries (Title, Contents, and Classes)\n",
        "\n",
        "    \n",
        "    # print(df22.describe())     # get an overview of the dataset\n",
        "\n",
        "    # check if every row entry of each column is string type (some are NaN, so no)\n",
        "    # print(df22.applymap(lambda x : type(x).__name__).eq({'Title': 'str', 'Content': 'str', 'Class':'str'}))\n",
        "\n",
        "    # convert NaN to empty strings (NaN -> str)\n",
        "        # df22.apply(str) converts all columns to str, as well\n",
        "    df22 = df22.replace(float('nan'), '', regex=True)\n",
        "\n",
        "    # concatenate strings of title & content with a \" \" in between (1 body of text)\n",
        "    text22 = df22['Title'] + \" \" + df22['Content']      # slicing DataFrame via .iloc[:,0] makes it a Series\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])    # so initialize it as a DataFrame. pd.DataFrame(some_Series) works\n",
        "    classes22 = df22['Class']\n",
        "\n",
        "    if R_known == True:\n",
        "    # R, r, YR = 1;     N, n, YN = 0\n",
        "        R_cases = re.compile('R|YR', re.IGNORECASE)\n",
        "        N_cases = re.compile('N|YN', re.IGNORECASE)\n",
        "        classes22 = classes22.replace(to_replace=R_cases, value=1)\n",
        "        classes22 = classes22.replace(to_replace=N_cases, value=0)\n",
        "    else:\n",
        "        # R_known == False; prepping not yet classified data\n",
        "        Y_N_cases = re.compile('Y|N', re.IGNORECASE)\n",
        "        classes22 = classes22.replace(to_replace=Y_N_cases, value=0)     # all N's for simplicity\n",
        "\n",
        "    classes22 = pd.DataFrame(classes22, columns=['Class']).astype('int32')\n",
        "    # classes22.columns = ['Class']    # classes22=pd.DataFrame(classes22) causes an error cus   pd.DataFrame(some_DataFrame) makes no sense - should pass a list\n",
        "\n",
        "    #print(text22.head(10))\n",
        "    #print(classes22.head(10))\n",
        "    print('==================================================')\n",
        "\n",
        "    return text22, classes22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 0.5\n",
        "\n",
        "def drop_dupe_text(text22, classes22):\n",
        "\n",
        "    # df22.drop_duplicates() will remove extra rows that have the same values in all columns (redundant)\n",
        "    # As a result only duplicate rows left are pairs of datapoints with 0 & 1 as their labels\n",
        "    # This function removes all of rows from those pairs with 0 as their label, as they can be disruptive\n",
        "    # in training the model. Label 1 should take priority\n",
        "\n",
        "    textdupeindex = text22[text22.duplicated(keep=False)==True].index\n",
        "    dupeclasses = classes22.filter(items = textdupeindex, axis=0)\n",
        "    redundantclass0 = dupeclasses[dupeclasses.Class==0]\n",
        "    text22.drop(index=redundantclass0.index, inplace=True)\n",
        "    classes22.drop(index=redundantclass0.index, inplace=True)\n",
        "\n",
        "    return text22, classes22\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ccb01838363a4066a44a81992df4c06a",
        "source_hash": "abf12822",
        "is_code_hidden": true,
        "execution_start": 1674080104108,
        "execution_millis": 16574,
        "is_output_hidden": true,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "udY2E0sFZIqU",
        "outputId": "fc519e2b-032d-4796-9ca5-7814fbc5188d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Practice\n",
        "#### v. 20230118"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "acbdd5e51fa346b2b141d7dcf4ba0274",
        "deepnote_cell_type": "markdown",
        "id": "JRkT4Q-yZIqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip3 install torch torchvision torchaudio     # for PyTorch without GPU, just CPU\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d680c6cc343e44dda5236360ff9ce245",
        "source_hash": "a40f784d",
        "execution_start": 1674080120693,
        "execution_millis": 11,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "vKI5w-BMZIqc"
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U"
      ],
      "metadata": {
        "id": "I7P3DUOpgV7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d157115-f147-4916-e944-237d35023c42"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0.dev0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU can be detected\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()              # '/device:GPU:0' means GPU is enabled\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eWAtNCmrzso",
        "outputId": "06da9425-e761-4674-9ba6-ed7c0b15911f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# torch.cuda.is_available = lambda : False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1KyaineWiqgA",
        "outputId": "80b34946-1719-455c-83ae-292a51962ca2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo            # check memory resources available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf6uQarosHGv",
        "outputId": "b87b5522-c8af-4741-8b56-868378dce592"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13297192 kB\n",
            "MemFree:          565624 kB\n",
            "MemAvailable:    7973144 kB\n",
            "Buffers:          362748 kB\n",
            "Cached:          7137612 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1187008 kB\n",
            "Inactive:       11033440 kB\n",
            "Active(anon):        916 kB\n",
            "Inactive(anon):  4708412 kB\n",
            "Active(file):    1186092 kB\n",
            "Inactive(file):  6325028 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1552 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       4720160 kB\n",
            "Mapped:          1103328 kB\n",
            "Shmem:             15584 kB\n",
            "KReclaimable:     222452 kB\n",
            "Slab:             277096 kB\n",
            "SReclaimable:     222452 kB\n",
            "SUnreclaim:        54644 kB\n",
            "KernelStack:        5184 kB\n",
            "PageTables:        41860 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648596 kB\n",
            "Committed_AS:    6739124 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       53756 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1336 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      342848 kB\n",
            "DirectMap2M:    10139648 kB\n",
            "DirectMap1G:     5242880 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qu9kfdGl1Vv2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "SCmAhc2i0JDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0ea7ee-09f2-4dc2-be4c-ccbd2da1cf2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-19 21:22:55--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27264 (27K) [text/plain]\n",
            "Saving to: ‘run_glue.py.1’\n",
            "\n",
            "run_glue.py.1       100%[===================>]  26.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-19 21:22:55 (77.9 MB/s) - ‘run_glue.py.1’ saved [27264/27264]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# install wandb for tracking data on dashboard\n",
        "!pip install datasets wandb evaluate -qU\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gGvsX_9j0JDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66226b34-fbe5-4ffb-b479-6429e9375988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# the run_glue.py script requires transformers dev\n",
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "of5C4XID0JDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7456ad0e-1a13-43c8-e3e7-c01c4ca7abc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# log in to have data synced to account\n",
        "# wandb.login()\n",
        "\n",
        "# log every trained model\n",
        "%env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://github.com/PradipNichite/Youtube-Tutorials/blob/main/FineTune_BERT_Model_Youtube.ipynb\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df22 = pd.read_csv('/S22_train20221011.csv', sep='\\t', index_col=0).drop_duplicates()\n",
        "\n",
        "# repair rows where values are shifted by 1 column\n",
        "shift_rows = df22.loc[df22[df22.Class.apply(lambda x: x == 'None')].index]   # rows where columns shifted to left\n",
        "shift_values = shift_rows[df22.columns[1:-1]]\n",
        "shift_rows[df22.columns[2:]] = shift_rows[df22.columns[1:-1]]\n",
        "shift_rows.Content = ''\n",
        "df22.loc[df22[df22.Class.apply(lambda x: x == 'None')].index] = shift_rows\n",
        "\n",
        "# filter training data to desired dates\n",
        "df22 = df22[df22.Date.apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').date() > datetime(2022,2,21).date())]\n",
        "\n",
        "# For class imbalance, use roughly same ratio of R & N\n",
        "######################################################### BERT doesn't need class imbalance addressed\n",
        "# df22 = pd.concat([df22[df22.Class=='R'], df22[df22.Class=='N'].iloc[::3, :]])\n",
        "\n",
        "# combine title & content as text22, clean the text, then combine it with labels to a single df  \n",
        "text22, classes22 = data_split(df22)\n",
        "df22, classes22 = drop_dupe_text(text22, classes22)\n",
        "\n",
        "# Preprocessing & data cleaning not required; BERT uses all info in sentence (punctuation, stopwords, etc)   \n",
        "df22['Class'] = classes22['Class']\n",
        "\n",
        "df22.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################ DELETE THIS LINE LATER (purpose: reduce data to reduce training time to test features)\n",
        "# df22 = df22.sample(frac=0.01, random_state=5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9f955299a3e54a1aaebfc738a20d1320",
        "source_hash": "76f0006d",
        "execution_start": 1674080120705,
        "execution_millis": 808,
        "is_output_hidden": false,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "k6xcfS07ZIqd",
        "outputId": "42782272-c73c-4523-c0d4-169a2bb7ce00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Text  Class\n",
              "452  Zfold 3 or S22 ultra Trying to decide between ...      0\n",
              "453  S22 video cam Anyone tried out the video camer...      0\n",
              "454  Thinking about trading my S21Ultra for S22+ Ev...      0\n",
              "455  S21 Ultra vs S22+ Both phones are currently at...      0\n",
              "456  S21 or S22 Base/Standard Model Hey All,\\n\\nLoo...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>Zfold 3 or S22 ultra Trying to decide between ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>S22 video cam Anyone tried out the video camer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>Thinking about trading my S21Ultra for S22+ Ev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>S21 Ultra vs S22+ Both phones are currently at...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>S21 or S22 Base/Standard Model Hey All,\\n\\nLoo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "execution_count": 65
    },
    {
      "cell_type": "code",
      "source": [
        "df22['Class'].value_counts()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ddbfd30c829a40c9af60fd8fc4ad8bb3",
        "source_hash": "fda411fd",
        "execution_start": 1674080121523,
        "execution_millis": 6,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJtMeTRwZIqe",
        "outputId": "a060842e-c072-49d4-bb23-7dc48a50c7ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    13926\n",
              "1     3658\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "execution_count": 66
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d968ff4c82ea4fe89fdeecd8ad261bda",
        "source_hash": "65934339",
        "execution_start": 1674080121543,
        "execution_millis": 5340,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk_eN8Q0ZIqe",
        "outputId": "cac16cdf-0165-4528-bdfa-d929b4ae33c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 67
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "506970be01814296ad84c7c9f3312165",
        "source_hash": "d991cab6",
        "execution_start": 1674080126876,
        "execution_millis": 88,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxeRDLYZIqf",
        "outputId": "0ae8617a-460a-47b0-e9ca-4943e8ea731b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "execution_count": 68
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.to( torch.device('cuda') )     # need NVIDIA driver for 'cuda'; currently have AMD on work laptop\n",
        "# model = model.to('cpu')         # train on CPU\n",
        "\n",
        "model = model.to('cuda')          # or  model.cuda()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "abaddecf0f7a4867b3088265ded4cec5",
        "source_hash": "ff8dd7cb",
        "execution_start": 1674080126980,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "65yDwWirZIqf"
      },
      "outputs": [],
      "execution_count": 69
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data = [\"This is possibly the worst battery I have ever seen on a mobile device\",\n",
        "            \"How is my device running so smoothly?\"]\n",
        "tokenizer(test_data, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "cbadffae0dd44bbbb994e70f20146772",
        "source_hash": "6c516043",
        "execution_start": 1674080126981,
        "execution_millis": 100,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z6XRhJgZIqg",
        "outputId": "e784b6b3-b53d-48ad-b0e9-28c20867749a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2023, 2003, 4298, 1996, 5409, 6046, 1045, 2031, 2412, 2464, 2006, 1037, 4684, 5080, 102], [101, 2129, 2003, 2026, 5080, 2770, 2061, 15299, 1029, 102, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "execution_count": 70
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df22[\"Text\"])\n",
        "y = list(df22[\"Class\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "af668836fd5341ac9016a845ebe79057",
        "source_hash": "25d321c9",
        "execution_start": 1674080127028,
        "execution_millis": 27370,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "o-G23j4EZIqg"
      },
      "outputs": [],
      "execution_count": 71
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized.keys()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "0ddc2b86e99d47f49d560a7a4a7427a9",
        "source_hash": "882ded45",
        "execution_start": 1674080154402,
        "execution_millis": 14,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2IkScN2ZIqh",
        "outputId": "658c96eb-981c-46ff-b843-23812171bdcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "execution_count": 72
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tokenized['attention_mask'][0])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "31306b38d6424983b8ec35e35b89d5d5",
        "source_hash": "c5b8c3f4",
        "execution_start": 1674080169475,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn6O2T8lZIqh",
        "outputId": "4a4d8b82-c32a-4f18-c100-0aca5c3b639a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "execution_count": 73
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train),len(X_val)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "c20d101dd6e84dff850d5446d87227b5",
        "source_hash": "1851768b",
        "execution_start": 1674080189480,
        "execution_millis": 0,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPVhi1tNZIqi",
        "outputId": "daec6f46-ffe4-4449-f836-25cdadd4ff83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14067, 3517)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "execution_count": 74
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch dataset\n",
        "class VOC_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "785f8f506f724850be7cdd073ff8bfd4",
        "source_hash": "3b060da6",
        "execution_start": 1674080232215,
        "execution_millis": 12,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "OC-jBK8SZIqi"
      },
      "outputs": [],
      "execution_count": 75
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOC_Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = VOC_Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9b6f589cb6274e459cf4b21ca9416ac7",
        "source_hash": "78f426a3",
        "execution_start": 1674080252981,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "0J6cyoT6ZIqi"
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "e74bd73ccb5e49869e5db0dc8d5da4db",
        "source_hash": "a1b8da62",
        "execution_start": 1674080260113,
        "execution_millis": 47,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT0-A0GyZIqj",
        "outputId": "59b9b6da-c31e-432c-eaeb-ee786d1efe3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  1055, 19317, 11087,  2417,  7262,  3475,  1005,  1056,  1012,\n",
              "          1012,  1012,  2417,  1029,  2633,  2288,  2026,  1055, 19317, 11087,\n",
              "          5359,  2651,  1998,  2009,  1005,  1055,  2025,  2130,  2485,  2000,\n",
              "          2417,  1012,  2009,  1005,  1055, 11034,  2012,  2190,  1012,  2428,\n",
              "          1010,  2428,  9364,  1012,   102,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "execution_count": 77
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(m):\n",
        "    print(type(m))\n",
        "    pred, labels = m\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "     "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d89ebde51e854f5c9bfb45c57a0b8eb2",
        "source_hash": "2986a0e5",
        "execution_start": 1674080319332,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "ItJjuFt_ZIqj"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Trainer\n",
        "args = TrainingArguments(\n",
        "    report_to = 'wandb',                     # enable logging to W&B\n",
        "    output_dir=\"output\",                     # output directory\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8\n",
        "    # overwrite_output_dir = True,\n",
        "    # evaluation_strategy = 'steps',          # check evaluation metrics at each epoch\n",
        "    # learning_rate = 5e-5,                   # we can customize learning rate\n",
        "    # max_steps = 30000,\n",
        "    # logging_steps = 100,                    # we will log every 100 steps\n",
        "    # eval_steps = 5000,                      # we will perform evaluation every 500 steps\n",
        "    # save_steps = 10000,\n",
        "    # load_best_model_at_end = True,\n",
        "    # metric_for_best_model = 'accuracy',\n",
        "    # run_name = 'custom_training'            # name of the W&B run\n",
        "\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,            # for padding batched data\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "f95f543b3daa425ebecc01270b25bf91",
        "source_hash": "223c3ba0",
        "execution_start": 1674080330040,
        "execution_millis": 145,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFYxNIctZIqj",
        "outputId": "a99358e2-a177-4b55-80a6-924e7147a61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "start = timer()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "end = timer()\n",
        "print(\"%4f seconds, %4f minutes elapsed\" % (float(end-start), float((end-start)/60)))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8185c9ee39774fcba9200e83819fce3f",
        "source_hash": "c4a351e7",
        "execution_start": 1674080563381,
        "execution_millis": 17834,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "8NO7NW3bZIqk",
        "outputId": "9f1a5cb0-8115-4662-d66e-51844db6af2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 14067\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1759\n",
            "  Number of trainable parameters = 109483778\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1759' max='1759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1759/1759 21:47, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.370800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.307900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.279600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-1000\n",
            "Configuration saved in output/checkpoint-1000/config.json\n",
            "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-1500\n",
            "Configuration saved in output/checkpoint-1500/config.json\n",
            "Model weights saved in output/checkpoint-1500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /tmp/tmp7qc0kwc5\n",
            "Configuration saved in /tmp/tmp7qc0kwc5/config.json\n",
            "Model weights saved in /tmp/tmp7qc0kwc5/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1308.139700 seconds, 21.802328 minutes elapsed\n"
          ]
        }
      ],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "97a062b8225e4125971486d915e3ac86",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "4L3oPcUvZIqk",
        "outputId": "f4e3d3c5-348e-47a4-deb4-49b0d28c5b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3517\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [440/440 01:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.trainer_utils.EvalPrediction'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2499202936887741,\n",
              " 'eval_accuracy': 0.9033266988911004,\n",
              " 'eval_precision': 0.7768361581920904,\n",
              " 'eval_recall': 0.7513661202185792,\n",
              " 'eval_f1': 0.763888888888889,\n",
              " 'eval_runtime': 112.6355,\n",
              " 'eval_samples_per_second': 31.225,\n",
              " 'eval_steps_per_second': 3.906,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "2920442657d045288b468403b8e7ce45",
        "deepnote_cell_type": "code",
        "id": "ee-3alVdZIqk"
      },
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Super charging is working very well.\"\n",
        "# text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "print(outputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)    # also gelu(), silu()\n",
        "print(predictions)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "b95d7749d3074a20bdfa3cdc432b149e",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndgwa_feZIql",
        "outputId": "1c11fb14-08bc-4ca0-ad39-947b57c2b98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8727, -1.0109]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "tensor([[ 0.6155, -0.2697]], device='cuda:0', grad_fn=<SiluBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.61548567, -0.26971212]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "execution_count": 105
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('BertPractice')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehJCv_jKWoge",
        "outputId": "83ef3ca0-596f-4572-b086-b0661db066d6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to BertPractice\n",
            "Configuration saved in BertPractice/config.json\n",
            "Model weights saved in BertPractice/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.save_model('/content/drive/MyDrive/Youtube Tutorials/toxic')\n",
        "# model_2 = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Youtube Tutorials/toxic\")\n",
        "# model_2.to('cuda')"
      ],
      "metadata": {
        "id": "FDIfAtXeWqBP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = BertForSequenceClassification.from_pretrained('BertPractice')\n",
        "model_2.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9af__siKWrvn",
        "outputId": "27483ca9-7079-409b-9bd7-fde1520935a3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file BertPractice/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file BertPractice/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BertPractice.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Super charging is working very well.\"\n",
        "text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model_2(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "53e74eee144d445da85927276d7daff3",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf4WU--hZIql",
        "outputId": "04c7c74f-ea28-4624-ead8-b3b0798c6251"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09049978, 0.90950024]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "execution_count": 115
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#today's VOC\n",
        "# import file and combine title & content\n",
        "voctoday = pd.read_csv('/0119.csv', sep='\\t', index_col=None).drop_duplicates()\n",
        "voctoday['title'] = voctoday['title'].astype(str) + \" \" + voctoday['content'].astype(str)\n",
        "voctoday = voctoday[['title', 'class']]\n",
        "\n",
        "voclist = list(voctoday['title'])\n",
        "predlist = []\n",
        "\n",
        "for i in range(len(voclist)):\n",
        "  inputs = tokenizer(voclist[i], padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "  outputs = model_2(**inputs)\n",
        "  predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "  predictions = predictions.cpu().detach().numpy()\n",
        "  predlist.append(predictions)\n",
        "\n",
        "organizedzip = zip([x[:25] for x in voclist],\n",
        "                   predlist,\n",
        "                   voctoday['class'])\n",
        "    \n",
        "# results as voc text, predictions, and actual value\n",
        "print(list(organizedzip))\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6093bde4694f46c195c95d0798e529cb",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvNon4aUZIql",
        "outputId": "35a8d080-3cbb-4a04-a035-d9de5f5b2ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('2nd January update I just', array([[0.9971807 , 0.00281931]], dtype=float32), 'N'), ('No Questions just wanted ', array([[0.9981193 , 0.00188064]], dtype=float32), 'N'), ('S22u vs S23u Having time ', array([[0.9957015 , 0.00429845]], dtype=float32), 'N'), ('No more lag and stutter a', array([[0.7561109, 0.2438891]], dtype=float32), 'N'), ('Qualcomm Bluetooth Codecs', array([[0.99762386, 0.00237617]], dtype=float32), 'N'), ('Sound Issues Hey everyone', array([[0.07707566, 0.92292434]], dtype=float32), 'R'), ('Samsung Leather Case vs O', array([[0.9981981, 0.0018019]], dtype=float32), 'N'), ('Weather widget help nan', array([[0.97075576, 0.02924431]], dtype=float32), 'R'), ('battery concern I can squ', array([[0.9247212 , 0.07527879]], dtype=float32), 'R'), ('S22 Ultra Camera Issued H', array([[0.06688055, 0.9331195 ]], dtype=float32), 'R'), ('Single Take Functionality', array([[0.97552943, 0.02447058]], dtype=float32), 'N'), ('So I already had the Janu', array([[0.9965773 , 0.00342264]], dtype=float32), 'N'), ('S22 Ultra not super Fast ', array([[0.09622952, 0.9037705 ]], dtype=float32), 'R'), ('Odd camera / video issue ', array([[0.06867576, 0.93132424]], dtype=float32), 'R'), ('Which variant should I pi', array([[0.99741805, 0.00258196]], dtype=float32), 'N'), ('Next best thing to ROOT o', array([[0.9976853 , 0.00231465]], dtype=float32), 'N'), ('Samsung Pass So I know mo', array([[0.97717094, 0.0228291 ]], dtype=float32), 'N'), ('S22+ drops to its lowest ', array([[0.94260883, 0.05739109]], dtype=float32), 'N'), ('Should I trade my s22 for', array([[0.99857163, 0.00142838]], dtype=float32), 'N'), ('Galaxy S22 Ultra live dem', array([[0.99846256, 0.00153746]], dtype=float32), 'N'), ('Planning to pre-order S23', array([[0.998553, 0.001447]], dtype=float32), 'N'), ('Am I the only one who thi', array([[0.8282212 , 0.17177877]], dtype=float32), 'N'), ('Calls not working on car ', array([[0.06585397, 0.93414605]], dtype=float32), 'R'), ('US S22+ only one physical', array([[0.99576265, 0.00423735]], dtype=float32), 'N'), ('Galaxy S22 battery life f', array([[0.98432595, 0.01567405]], dtype=float32), 'N'), ('i am using a s22 and i am', array([[0.9980702 , 0.00192984]], dtype=float32), 'N'), ('Which is better: Samsung ', array([[0.9979746 , 0.00202539]], dtype=float32), 'N'), ('S22 exynos 128 for 600 € ', array([[0.9985879 , 0.00141204]], dtype=float32), 'N'), ('S22 ultra vs s23 ultra! S', array([[0.99852437, 0.00147562]], dtype=float32), 'N'), ('Return the S22+? I recent', array([[0.9986027 , 0.00139738]], dtype=float32), 'N'), ('My dilemma: S21 FE or S22', array([[0.99724424, 0.00275579]], dtype=float32), 'N'), ('No 4K 120fps but I found ', array([[0.9933248 , 0.00667518]], dtype=float32), 'N'), ('I deleted some text messa', array([[0.99478084, 0.00521919]], dtype=float32), 'N'), ('Group messages I just rec', array([[0.11345708, 0.8865429 ]], dtype=float32), 'R'), ('Block Unknown Numbers Not', array([[0.07255138, 0.92744863]], dtype=float32), 'R'), ('Notifications glitch? Aft', array([[0.07246736, 0.9275326 ]], dtype=float32), 'R'), ('Black and White Somehow e', array([[0.14287566, 0.8571243 ]], dtype=float32), 'R'), ('Multiple Voicemail Notifi', array([[0.542721  , 0.45727903]], dtype=float32), 'R'), ('Angry The display of my S', array([[0.17455518, 0.8254448 ]], dtype=float32), 'R'), ('Backspace Why does my bac', array([[0.8713595 , 0.12864044]], dtype=float32), 'N'), ('Multiple Notification sou', array([[0.9725605 , 0.02743946]], dtype=float32), 'R'), (\"Don't have the us Galaxy \", array([[0.99168056, 0.00831943]], dtype=float32), 'N'), ('Fast charging I have s22+', array([[0.07091352, 0.9290865 ]], dtype=float32), 'R')]\n"
          ]
        }
      ],
      "execution_count": 140
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "8207dc085d8b42718086312e08437452",
        "deepnote_cell_type": "code",
        "id": "5Bw4LKQzZIqm"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "5aeac4c1c9b34e4b9afe24f40e1d3c27",
        "source_hash": "24acd7c3",
        "is_code_hidden": true,
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "XHyZQQDLZIqm"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "501fe0946abe4e6398eb6a364a652e3c",
        "source_hash": "b623e53d",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "HOzIXC_iZIqm"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e5caba9f-cd36-4d50-aaa3-2cf59957a2f4' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "llB-FWxEZIqn"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {},
    "orig_nbformat": 2,
    "deepnote_notebook_id": "99baf882d48d4fa4b40b67d8bd9057bf",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}
