{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojw92/NLP-for-Text-Classification/blob/main/BERT_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "d2b3fe256b094e82a87b624b50b7af86",
        "deepnote_cell_type": "markdown",
        "id": "_u716cCIZIqP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8M_IjgNzPa9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing (not needed for BERT)\n",
        "\n",
        "# preprocessor.py\n",
        "\n",
        "# Preprocessing steps for RNN & CNN\n",
        "\n",
        "# Model for S22 VOC only, but with added preprocessing steps\n",
        "\n",
        "# https://www.geeksforgeeks.org/python-call-function-from-another-file/\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')    # for lemmatization function; don't need this line if package installed\n",
        "nltk.download('omw-1.4')    # for lemmatization function; don't need this line if package installed\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer     # based on The Porter Stemming Algorithm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91\n",
        "\n",
        "# 0 - split & prepare data for preprocessing                              <- add a preliminary stopword removal step (RNN & CNN)?\n",
        "# 0.5 - remove duplicate data\n",
        "# 1 - remove hyperlinks, emails & pricetags\n",
        "# 2 - remove emoji\n",
        "# 3 - remove punctuations\n",
        "# 4 - apply lower case\n",
        "\n",
        "# ===== use min-df to find low-frequency words =====\n",
        "\n",
        "# 5 - fix misspellings                                                    <- (need to implement!)\n",
        "# 6 - replace words with generic nouns                                    <- (need to implement!)\n",
        "# 7 - remove stopwords       # better to replace then remove?             <- final stopword clean-up step (separate list for RNN & CNN)\n",
        "# 8 - lemmatize\n",
        "# (8.5 - stemming)\n",
        "\n",
        "# 9 - tokenization & padding\n",
        "\n",
        "# ============================================================================================================= 0                 <- add a preliminary stopword removal step\n",
        "\n",
        "def data_split(df22, R_known=True):\n",
        "\n",
        "    # Split the input dataframe into Text (Title + Contents) and Classes dataframes\n",
        "    # input must have 3 columns of string entries (Title, Contents, and Classes)\n",
        "\n",
        "    \n",
        "    # print(df22.describe())     # get an overview of the dataset\n",
        "\n",
        "    # check if every row entry of each column is string type (some are NaN, so no)\n",
        "    # print(df22.applymap(lambda x : type(x).__name__).eq({'Title': 'str', 'Content': 'str', 'Class':'str'}))\n",
        "\n",
        "    # convert NaN to empty strings (NaN -> str)\n",
        "        # df22.apply(str) converts all columns to str, as well\n",
        "    df22 = df22.replace(float('nan'), '', regex=True)\n",
        "\n",
        "    # concatenate strings of title & content with a \" \" in between (1 body of text)\n",
        "    text22 = df22['Title'] + \" \" + df22['Content']      # slicing DataFrame via .iloc[:,0] makes it a Series\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])    # so initialize it as a DataFrame. pd.DataFrame(some_Series) works\n",
        "    classes22 = df22['Class']\n",
        "\n",
        "    if R_known == True:\n",
        "    # R, r, YR = 1;     N, n, YN = 0\n",
        "        R_cases = re.compile('R|YR', re.IGNORECASE)\n",
        "        N_cases = re.compile('N|YN', re.IGNORECASE)\n",
        "        classes22 = classes22.replace(to_replace=R_cases, value=1)\n",
        "        classes22 = classes22.replace(to_replace=N_cases, value=0)\n",
        "    else:\n",
        "        # R_known == False; prepping not yet classified data\n",
        "        Y_N_cases = re.compile('Y|N', re.IGNORECASE)\n",
        "        classes22 = classes22.replace(to_replace=Y_N_cases, value=0)     # all N's for simplicity\n",
        "\n",
        "    classes22 = pd.DataFrame(classes22, columns=['Class']).astype('int32')\n",
        "    # classes22.columns = ['Class']    # classes22=pd.DataFrame(classes22) causes an error cus   pd.DataFrame(some_DataFrame) makes no sense - should pass a list\n",
        "\n",
        "    #print(text22.head(10))\n",
        "    #print(classes22.head(10))\n",
        "    print('==================================================')\n",
        "\n",
        "    return text22, classes22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 0.5\n",
        "\n",
        "def drop_dupe_text(text22, classes22):\n",
        "\n",
        "    # df22.drop_duplicates() will remove extra rows that have the same values in all columns (redundant)\n",
        "    # As a result only duplicate rows left are pairs of datapoints with 0 & 1 as their labels\n",
        "    # This function removes all of rows from those pairs with 0 as their label, as they can be disruptive\n",
        "    # in training the model. Label 1 should take priority\n",
        "\n",
        "    textdupeindex = text22[text22.duplicated(keep=False)==True].index\n",
        "    dupeclasses = classes22.filter(items = textdupeindex, axis=0)\n",
        "    redundantclass0 = dupeclasses[dupeclasses.Class==0]\n",
        "    text22.drop(index=redundantclass0.index, inplace=True)\n",
        "    classes22.drop(index=redundantclass0.index, inplace=True)\n",
        "\n",
        "    return text22, classes22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 1\n",
        "\n",
        "def hep_remove(text22):\n",
        "\n",
        "    # Remove hyperlinks, e-mails, and pricetags from a dataframe of strings\n",
        "    ### It would be nice to instead of removing them, replace e-mails and hyperlinks with \"url\"\n",
        "    ### and replace price tags with \"price\"\n",
        "\n",
        "    # algorithm\n",
        "    # regex that matches all non-whitespace text before and after '.com', '.org', '.gov', '.edu'\n",
        "    # \"\" before and after '@', but the above line should take care of this automatically\n",
        "    # \"\" after '$£€₱₽¥₩'; number, comma, and period should suffice, but account for pricetags written in text\n",
        "\n",
        "    # list of hyperlinks, e-mails, and price tags\n",
        "    # use this step specifically to remove words that have punctuation mixed in\n",
        "    heplist = ['.com','.edu','.org','.gov', '.co', 'https:', 'http:',\n",
        "                '$','£','€','₱','₽','¥','₩', ',000', '.00']   # include '-'? need to think\n",
        "    # remove hyperlinks (& e-mails, as side effect!)\n",
        "    text22 = [' '.join(y for y in x.split() if not any(ele in y for ele in heplist)) \n",
        "                for x in text22.Text]\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])\n",
        "\n",
        "    return text22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 2\n",
        "\n",
        "def emoji_remove(text22):\n",
        "\n",
        "    # Remove image & textual imoji\n",
        "\n",
        "    # Remove emoji\n",
        "    # https://towardsdatascience.com/text-preprocessing-for-data-scientist-3d2419c8199d\n",
        "    def emoji_rem(string):\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "        return emoji_pattern.sub(r'', string)\n",
        "    \n",
        "    text22.Text = text22['Text'].apply(emoji_rem)\n",
        "    # text22 = list(map(emoji_rem, text22))     # for a list, map the function\n",
        "\n",
        "    \"\"\"\n",
        "    # Remove texual emoji and other colon  (\":fire:\", \":hundred_points\",)\n",
        "    def textualemoji(string):\n",
        "        return re.sub(r'[^:\\w:$]', ' ', string)     # starts & ends with :, matches text, number and _ between :'s\n",
        "\n",
        "    text22.Text = text22['Text'].apply(textualemoji)\n",
        "    \"\"\"\n",
        "    # Too many 'letter emojis' - need to use regex\n",
        "    \"\"\"letteremoji = ['Q_Q','QQ','T_T','UWU','uwu','UwU','uWu', 'orz','OTL',\n",
        "                   'o_o','O_O','o_O','O_o', 'o-o','O-O', '==','=_=','-_-','--',\n",
        "                   '*_*','$_$','@_@','?_?','+_+','>_>','<_<', '~_~', \"'-'\",\n",
        "                   ':x',';x', ':D',';D','D:','D;', ':)',';)', ':(',';(', '(:','(;','):',');',\n",
        "                   ':s',':S']\"\"\"\n",
        "    \n",
        "    #text22 = [' '.join(y for y in x.split() if not any(ele in y for ele in letteremoji)) \n",
        "    #            for x in text22]\n",
        "    # text22 = pd.DataFrame(text22, columns=['Text'])\n",
        "    \n",
        "    return text22\n",
        "\n",
        "# ===================== Implement regex in letteremoji later ========================\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 3\n",
        "\n",
        "def punc_remove(text22):\n",
        "    \n",
        "    # Remove punctuation\n",
        "    \n",
        "    # using RegexpTokenizer might lose words like \"Mr.\"\n",
        "    # need to remove just the punctuation, not the whole word attached to it!\n",
        "    # what about words like, 'work-life-balance' ?\n",
        "\n",
        "    # double backslash for a string of single backslash\n",
        "    # punclist = ['!','@','#','$','%','^','&','*','(',')','-','_','=','+','\\\\','|','`','~',',','.','<','>','/','?',';',':','\"',\"'\"]\n",
        "\n",
        "\n",
        "    def puncrem(string):\n",
        "        return re.sub(r'[^\\w\\s]', '', string)\n",
        "\n",
        "    text22 = text22['Text'].apply(puncrem)\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])\n",
        "\n",
        "    return text22\n",
        "\n",
        "# If we get rid of punctuation in things like \"it's\" or \":S\", we're gonna get\n",
        "# single letter words or misspelled words (it's -> its)\n",
        "# for CNN, we can just remove them, but RNN we need a fix...\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 4\n",
        "\n",
        "def lower_case(text22):\n",
        "\n",
        "    # Take a data frame of strings and make them lower case characters\n",
        "    \n",
        "    # First replace any NaNs generated from other preprocessing steps with empty strings\n",
        "    text22 = text22.replace(np.nan, '', regex=True)\n",
        "\n",
        "    # Apply lower case\n",
        "    text22 = text22['Text'].str.lower()                 # Series\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])\n",
        "\n",
        "    return text22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 5               <- (need to implement!)\n",
        "\n",
        "def fix_spelling(text22):\n",
        "    \n",
        "    # Take a data frame of strings and fix all misspelled words\n",
        "\n",
        "    \n",
        "    # logic here\n",
        "\n",
        "\n",
        "\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])\n",
        "\n",
        "    return text22\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 6               <- (need to implement!)\n",
        "\n",
        "def pn_replace(text22):\n",
        "\n",
        "    # Take a data frame of strings and replace proper nouns or certain nouns with a common, generic noun\n",
        "\n",
        "    # Texas, New York City, NYC, LA, Los Angeles, NJ --> usloc\n",
        "    # China, Hong Kong, New Zealand, UK, Canada, India --> nonusloc\n",
        "    # Max, Mark, Johnny, Adam, Obama, Kanye --> person\n",
        "    # bees, duck, my dog, dog, cat, falcon, eagle --> animal      (for a stopword list, make sure \"my dog\" appears before \"dog\"\n",
        "    # he, she, their, us, it pronouns --> pronoun\n",
        "    # use this for ideas https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/\n",
        "    # exynos vs snapdragon\n",
        "\n",
        "    #querywords = query.split()\n",
        "    #print(querywords)\n",
        "    #resultwords  = [word for word in querywords if word.lower() not in stopwords]\n",
        "    #result = ' '.join(resultwords)\n",
        "\n",
        "\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])\n",
        "\n",
        "    return text22\n",
        "    \n",
        "\n",
        "\n",
        "# ============================================================================================================= 7\n",
        "\n",
        "# Stopword will need a lot of work! Expect performance to be bad/worse with stopwords\n",
        "# For the low-freq words the stopwords can't catch, use min-df to clean up\n",
        "\n",
        "def stopword_remove(text22, model=\"RNN\"):\n",
        "\n",
        "    # Take a data frame of strings and remove all preselected stopwords from them\n",
        "\n",
        "    # Remove stopwords (including my choice of words)\n",
        "    # may need to keep words like \"not\", \"doesn't\", \"does\"\n",
        "    #from nltk.corpus import stopwords\n",
        "    #nltk.download('stopwords')     # don't need this line if package installed\n",
        "    #stop = stopwords.words('english')\n",
        "    \"\"\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself,\n",
        "    yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their,\n",
        "    theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, \n",
        "    being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of,\n",
        "    at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down,\n",
        "    in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each,\n",
        "    few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don,\n",
        "    don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn,\n",
        "    doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn,\n",
        "    needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't \n",
        "    \"\"\"\n",
        "    # lots of words in nltk stopwords list have significance in VOC context, so make my own list:\n",
        "    # if using CNN, use stopwords. If using LSTM(RNN), may need to think about it. lemmatizing LSTM can get tricky too\n",
        "    \"\"\"\n",
        "    stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
        "            'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
        "            'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
        "            'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
        "            'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
        "            'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
        "            'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
        "            'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
        "            'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no',\n",
        "            'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'will', 'just',\n",
        "            \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', \n",
        "            'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\",\n",
        "            'weren', \"weren't\"]\n",
        "    \"\"\"\n",
        "    # use this basic list for now - study data closely and add more later\n",
        "    if model == \"RNN\":\n",
        "        # to/from, up/down, in/out opposite meanings -> significant? \"be\" verb not significant\n",
        "        # who/what/when/where/why/how, which, only\n",
        "        stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
        "            'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
        "            'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
        "            'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
        "            'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'if',\n",
        "            'or', 'as', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between',\n",
        "            'into', 'through', 'during',\n",
        "            'to', 'from', 'in', 'out',     # to/from, in/out,      on/off, up/down, above/below, over/under\n",
        "            'again', 'further', 'then', 'once', 'here', 'there',\n",
        "            'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such',\n",
        "            'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'will', 'just',\n",
        "            'd', 'll', 'm', 'o', 're', 've', 'y', 'ma']\n",
        "    elif model == \"CNN\":\n",
        "        stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
        "            'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
        "            'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
        "            'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
        "            'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
        "            'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between',\n",
        "            'into', 'through', 'during', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
        "            'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
        "            'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such',\n",
        "            'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'will', 'just',\n",
        "            'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'ma']\n",
        "    \n",
        "    # create my own list of stopwords and concatenate to existing list of 179 NLTK stopwords\n",
        "    my_stopwords = ['lol', 'lmao', 'lmfao', 'rofl', 'wtf','fuck','shit','jesus','christ','wth','what the fuck',\n",
        "                    'what the hell','samsung','apple','lg','xiaomi',\n",
        "                    'cus','cuz',\n",
        "                    '0','1','2','3','4','5','6','7','8','9',\n",
        "                    'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
        "                    'hi','hey','hello','hiya','greetings','all','sincerely','bye','farewell',\n",
        "                    'thanks','thank','appreciate','think','believe',\n",
        "                    'probably','almost','likely', 'sometimes','frequently','occasionally','gradually','occasion','gradual',\n",
        "                    'expensive','cheap','price','pricey',\n",
        "                    'really'\n",
        "                    ]\n",
        "    # concatenate RNN/CNN stopwords with my stopwords\n",
        "    stop = [*stop, *my_stopwords]\n",
        "\n",
        "    #text22 = text22.apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)])) # joins all rows for some reason\n",
        "    removeit = np.vectorize(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
        "    text22 = pd.DataFrame(removeit(text22), columns= ['Text'])\n",
        "\n",
        "    return text22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 8\n",
        "\n",
        "# Lemmatization - 'caring' --> 'care'\n",
        "\n",
        "def lemmatize_df(text22):\n",
        "\n",
        "    # Take a data frame of strings and lemmatize its texts\n",
        "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "    wnl = WordNetLemmatizer()   # plural --> singular, but verb tense unchanged\n",
        "\n",
        "    # This is my own, long (high-CPU-usage?) way to tokenize & lemmatize words!\n",
        "    tempdf = pd.DataFrame(columns=['Text'])\n",
        "    for i in text22['Text']:\n",
        "        jol = []\n",
        "        for j in w_tokenizer.tokenize(i):\n",
        "            jol.append(wnl.lemmatize(j))\n",
        "        tempdf.loc[len(tempdf.index)] = [jol]\n",
        "        # text22['Text'].loc[len(text22.index)] = [jol]   # find a way to append directly to existing df and trim it\n",
        "    # print(tempdf.head(10))\n",
        "    # print(\"length of tempdf: \" , len(tempdf))\n",
        "\n",
        "    text22 = pd.DataFrame(tempdf, columns=['Text'])\n",
        "\n",
        "    return text22\n",
        "\n",
        "# ===== A much shorter way to lemmatize! (more CPU-efficient?) =====\n",
        "\"\"\"\n",
        "def lemmatize_text(some_string):\n",
        "    return [wnl.lemmatize(w) for w in w_tokenizer.tokenize(some_string)]\n",
        "df22['cont_sw_lem'] = df22['cont_sw'].apply(lemmatize_text)    # .apply works on DataFrame or Series\n",
        "print('\\nAfter lower case & lemmatization: \\n')\n",
        "print(df22.head())\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 8.5\n",
        "\n",
        "# Stemming - 'caring' --> 'car'\n",
        "# No need to use both lemmatization & stemming - just use lemmatization\n",
        "\n",
        "def stemming_df(text22):\n",
        "\n",
        "    # Take a data frame of strings and do stemming on its texts\n",
        "    \n",
        "    # nature, natures, natural --> natur\n",
        "    snowball_stemmer = SnowballStemmer('english')\n",
        "    # kol = []     # This is my way of stemming on one Series\n",
        "    # for i in text22['Text']:\n",
        "    #     kol.append([snowball_stemmer.stem(word) for word in i])\n",
        "    # stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n",
        "    # text22['Text'] = kol\n",
        "    \n",
        "    def stemit(some_string):\n",
        "        return [snowball_stemmer.stem(word) for word in some_string]\n",
        "    \n",
        "    text22 = text22.Text.apply(stemit)\n",
        "    text22 = pd.DataFrame(text22, columns= ['Text'])\n",
        "\n",
        "    # text22['Text'] = text22.Text.apply(stemit)\n",
        "\n",
        "    #print(text22['Text'][2715])\n",
        "\n",
        "    return text22\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 9\n",
        "\n",
        "\n",
        "# Word tokenization\n",
        "\n",
        "def tokenize_pad_words(text22, min_df=0, max_xref=0):\n",
        "    \n",
        "    # Take a data frame of strings to tokenize its words, then assign an index to each word\n",
        "\n",
        "    #      tokenization\n",
        "    # =========================\n",
        "    # https://www.kaggle.com/code/hamishdickson/using-keras-oov-tokens\n",
        "    # https://stackoverflow.com/questions/49073673/include-punctuation-in-keras-tokenizer\n",
        "        # should I include punctuations? Only like 30 more features...\n",
        "    token22 = Tokenizer(num_words=11000, lower=True, oov_token='OOV')  #20221012 data 10920 words w freq>2\n",
        "    token22.fit_on_texts(text22['Text'])\n",
        "    print('\\nIndex determined by word freq(hi->lo) : \\n', token22.word_index)    # Dict object - index determined by word frequency highest-lowest\n",
        "\n",
        "    # Convert each voc entry to list of tokenized words, then find longest list (most words in entry)\n",
        "    x22 = token22.texts_to_sequences(text22['Text'])\n",
        "    max_x22 = max(len(elem) for elem in x22)\n",
        "    print('\\nVOC entries represented as tokenized indices : \\n', x22[0:2])      # List of lists - too long to print in full\n",
        "    print('\\nFrequency of each word : \\n', token22.word_counts)                 # Dict\n",
        "    print('\\nNumber of sentences each word appears in : \\n', sorted(token22.word_docs.items(), key=lambda z: z[1], reverse=True))  # [('the', 3632), ('i', 3010), ('to', 2989), ...]\n",
        "        # sorted(token22.word_docs.items())    [('0': 17), ('00': 1), ('000a': 1), ...] \n",
        "    print('\\nTotal number of VOC : \\n', token22.document_count)\n",
        "    print('\\nLongest VOC entry has %d (tokenized) words.' % max_x22)\n",
        "\n",
        "    word_size22 = len(token22.word_index) + 1\n",
        "\n",
        "\n",
        "    # Take a list of lists of tokenized words and do padding on them\n",
        "\n",
        "    #      padding\n",
        "    # =========================\n",
        "    # each VOC has different number of words, so x has a list of lists, which is why to_categorical(x) caused error\n",
        "    # normalize every voc to vectors of same length - max_x\n",
        "    if max_x22 >= max_xref:\n",
        "        max_x22 = max_x22\n",
        "    else:\n",
        "        max_x22 = max_xref\n",
        "    padded_x22 = pad_sequences(x22 , max_x22)\n",
        "    print('\\nPadded results : \\n', padded_x22)\n",
        "    print('type of padded_x22 is array of lists/matrix?  ', type(padded_x22))            # <---------- delete this later after finding out what it is\n",
        "    print('Length of padded_x22: ', len(padded_x22))\n",
        "    print('word_size22: ', word_size22, ' (number of unique words + 1)')\n",
        "    print('max_x22: ', max_x22)\n",
        "\n",
        "\n",
        "    # Feature to add later - minimum word frequency to simplify our tokenized list\n",
        "    # Simple line below can filter by word count > 1. But need to apply to padded_x22 & max_x22, too\n",
        "        # For now, use Tokenizer(num_words=11000) since 20221012 data has 10920 words with frequency > 2\n",
        "    # mindf1 = {k:v for (k,v) in token22.word_counts.items() if v > 1}\n",
        "    # print(len(mindf1))\n",
        "\n",
        "\n",
        "    # print(padded_x22.dtype)    # int32\n",
        "    # print(classes22.dtype)    # int64 \n",
        "\n",
        "\n",
        "    return padded_x22, word_size22, max_x22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 9\n",
        "\n",
        "\n",
        "# Visualizing Word2Vec Embeddings with t-SNE\n",
        "import gensim\n",
        "from sklearn.manifold import TSNE\n",
        "import random\n",
        "\n",
        "def semantic_similarity(X_train):\n",
        "\n",
        "    # X_train should be a single-column DataFrame of preprocessed Title + Content (text22 or df22['Text'])\n",
        "    X_train = X_train.apply(lambda x: gensim.utils.simple_preprocess(str(x)))\n",
        "    # Train the word2vec model\n",
        "    w2v_model = gensim.models.Word2Vec(X_train,\n",
        "                                    vector_size=100,   # size of vectors desired\n",
        "                                    window=5,  # # of words before & after target word to use as context\n",
        "                                    min_count=2        # min_df\n",
        "                                    )\n",
        "    w2v_model.build_vocab(X_train)  # prepare the model vocabulary\n",
        "    w2v_model.train(X_train, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)\n",
        "    vocab_size, embedding_size = w2v_model.wv.vectors.shape\n",
        "\n",
        "    n_samples = 250\n",
        "    # Sample random words from model dictionary\n",
        "    random_i = random.sample(range(vocab_size), n_samples)\n",
        "    # def token2word(token):\n",
        "    #     return w2v_model.wv.index_to_key[token]\n",
        "    random_w = [w2v_model.wv.index_to_key[i] for i in random_i]\n",
        "\n",
        "    # Generate Word2Vec embeddings of each word\n",
        "    word_vecs = np.array([w2v_model.wv[w] for w in random_w])   # 'Word2Vec' object not subscriptable; use .wv\n",
        "\n",
        "    # Apply t-SNE to Word2Vec embeddings, reducing to 2 dims\n",
        "    tsne = TSNE()\n",
        "    tsne_e = tsne.fit_transform(word_vecs)\n",
        "\n",
        "    # Plot t-SNE result\n",
        "    plt.figure(figsize=(32, 32))\n",
        "    plt.scatter(tsne_e[:, 0], tsne_e[:, 1], marker='o', c=range(len(random_w)), cmap=plt.get_cmap('Spectral'))\n",
        "\n",
        "    for label, x, y, in zip(random_w, tsne_e[:, 0], tsne_e[:, 1]):\n",
        "        plt.annotate(label,\n",
        "                    xy=(x, y), xytext=(0, 15),\n",
        "                    textcoords='offset points', ha='right', va='bottom',\n",
        "                    bbox=dict(boxstyle='round, pad=0.2', fc='yellow', alpha=0.1))\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 9\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.lines import Line2D\n",
        "def scatterplot_VOC(x, y, number_of_R, threshold, filename=None, directory=None):\n",
        "    # x = array of len(y)                      y = array of prediction probabilities\n",
        "    # number_of_R = number of actual R + 1     threshold = prediction threshold in float\n",
        "    plt.figure()\n",
        "    if filename is None:\n",
        "        filename = \"\"\n",
        "    plt.title(f'{filename[10:-4]} Scatter Plot')     # test_data/test_1012.csv --> test_1012\n",
        "    plt.scatter(x, y_prob3, c=(np.where(x<number_of_R+1,'g', 'r')))      # plots VOC (R & N)\n",
        "    plt.plot([0, len(y)],[threshold, threshold], c='k', linestyle='--')  # plots threshold\n",
        "\n",
        "    ###handles, labels = plt.gca().get_legend_handles_labels()    # *use this to add new to existing handle\n",
        "    R_points = mpatches.Patch(color='g', label='R')\n",
        "    N_points = mpatches.Patch(color='r', label='N')\n",
        "    threshline = Line2D([0], [0], color='k', linestyle='--', label='threshold')\n",
        "    ###handles.extend([R_points, N_points, threshline])           # *also plt.legend(handles=handles)\n",
        "\n",
        "    plt.legend(handles=[R_points, N_points, threshline], loc=\"best\")\n",
        "    plt.xlabel('VOC #')\n",
        "    plt.ylabel('Predictions')\n",
        "\n",
        "    if directory is not None:\n",
        "        f = os.path.join(directory, filename[10:-4])\n",
        "        plt.savefig(f'{f}-scatter.png')\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 9\n",
        "\n",
        "\n",
        "def add_category(text22):\n",
        "    # Look for keywords in text that indicate issue category and input 1 (yes) for that category\n",
        "    # vectorize this function on consolidated text (Title + Content) prior to text cleaning steps\n",
        "\n",
        "    # 20221107 For now, add only 5 major categories that comprise top 10 issue category in raw data:\n",
        "    # 3rd Party, Display, Battery, HW, Camera, Notification, Connectivity, Messages, Biometrics, Audio, Bluetooth\n",
        "            # note that Biometrics is mostly watch issues & Audio is mostly buds issues\n",
        "            # Checked each word from raw data file & only added if several rows existed\n",
        "\n",
        "    thirdparty_list = ['facebook', 'snapchat', 'youtube', 'instagram', 'reddit', 'amazon prime', 'cod',\n",
        "                        'fb', 'spotify', 'netflix', 'zoom', 'discord', 'tik', 'whatsapp', 'twitter',\n",
        "                        'genshin', 'game', 'dropbox', 'onedrive', 'twitch']\n",
        "    display_list = ['display', 'screen', 'crack', 'scratch', 'protector', 'hz', 'scroll', 'touch', 'hdr',\n",
        "                    'refresh rate', 'flicker', 'pixel', 'burn-in', 'burn in', 'tint', 'jump']\n",
        "    battery_list = ['SoT', 'battery', 'usage', 'consum', 'drain', 'lasts', 'lasting', 'dies']\n",
        "    camera_list = ['camera', 'shot', 'focus', 'blur', 'astrophotography', 'photo', 'video', 'saturat',\n",
        "                    'shutter', 'selfie', 'record', 'lens', 'ultrawide', 'ultra wide', 'flash', 'slow-mo']\n",
        "    noti_list = ['notif', 'vibrat', 'incoming', 'pop-up']\n",
        "    connect_list = ['connect','network','mobile data','hotspot','esim','sim card','5g','4g','3g',\n",
        "                    'signal', 'speed', 'internet', 'cellular', 'dual', 'reception', 'coverage']\n",
        "        # 'data', 'service', 'sim' might catch wrong VOC\n",
        "    messages_list = ['text', 'messag', 'whatsapp', 'RCS', 'MMS', 'chat', 'send', 'WhatsApp']\n",
        "\n",
        "\n",
        "    text22['thirdparty'] = text22['Text'].str.contains('|'.join(thirdparty_list), case=False)\n",
        "    text22['display'] = text22['Text'].str.contains('|'.join(display_list), case=False)\n",
        "    text22['battery'] = text22['Text'].str.contains('|'.join(battery_list), case=False)\n",
        "    # add for HW (what are S22 HW topics that span 70+% of S22 HW VOC?)\n",
        "    text22['camera'] = text22['Text'].str.contains('|'.join(camera_list), case=False)\n",
        "    text22['notification'] = text22['Text'].str.contains('|'.join(noti_list), case=False)\n",
        "    text22['connectivity'] = text22['Text'].str.contains('|'.join(connect_list), case=False)\n",
        "    text22['messages'] = text22['Text'].str.contains('|'.join(messages_list), case=False)\n",
        "    \n",
        "    # consider other categories of issues that S22 frequently suffer & topics that are discussed about S22\n",
        "\n",
        "\n",
        "\n",
        "    # Should check whether each category contains a good chunk of healthily distributed R & N VOC\n",
        "        # For each category, isolate all the 'True' rows & count up R & N\n",
        "        # Use the category for CART if a good chunk of S22 is accurately represented with the keywords\n",
        "            # assigned for that category. Also keep it even for small chunk, if it helps seclude tricky\n",
        "            # VOC's and make the rest of the data more \"pure\" of outlier patterns\n",
        "                # ex: if biometrics issues for S22 largely occur post-update, it'll help remove update-\n",
        "                # related VOCs, which exhibit strong, temporary pattern. Can check correlation between\n",
        "                # biometrics and updates as well, using PCA... there's no end to how complex I can go...\n",
        "    # To improve quality of this data, I should manually determine the category of each VOC instead of\n",
        "        # categorizing by the words that are mentioned. This will take FOREVER but will lend better data\n",
        "            # Keep in mind I have to re-open all of old Reddit VOC to record the \"flair\" of each S22 user\n",
        "            # Since I'm doing quick concept test for now, just go with keywords mentioned\n",
        "    # Other than major categories, also super worth categorizing by update/non-update\n",
        "        # this will help better predict issues around update release times\n",
        "\n",
        "\n",
        "    return text22\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 9\n",
        "\n",
        "\n",
        "def shift_values_over(df22, index):\n",
        "    # Shift columns of values over to the right by one unit from 2nd column\n",
        "    # Takes DataFrame index object like below:\n",
        "    # df22[df22.Class.apply(lambda x: x == 'None')].index\n",
        "\n",
        "    shift_rows = df22.loc[index]   # rows where columns shifted to left\n",
        "    shift_values = shift_rows[df22.columns[1:-1]]\n",
        "    shift_rows[df22.columns[2:]] = shift_rows[df22.columns[1:-1]]\n",
        "    shift_rows.Content = ''\n",
        "    df22.loc[df22[df22.Class.apply(lambda x: x == 'None')].index] = shift_rows\n",
        "    \n",
        "    return df22\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================================================= 9\n",
        "\n",
        "\n",
        "def ROC_AUC(y_test, y_score, fpr_tpr=None, filename=None, directory=None):\n",
        "    # Creates an ROC curve & computes AUC of the test data based on how it performs on the trained model\n",
        "    # Also calculates precision, recall & accuracy, and plots the position on ROC based on performance\n",
        "    # y_test, y_score, tp_fp need to be lists\n",
        "\n",
        "    # Create ROC curve and compute AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test[:], y_score[:], pos_label=1)    # 'thresholds' go in '_'\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    #print('fpr is', fpr)\n",
        "    #print('tpr is', tpr)\n",
        "    #print('thresholds', thresholds)\n",
        "    print('AUC : ', roc_auc)\n",
        "\n",
        "    # ROC curve\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color=\"darkorange\",\n",
        "        lw=lw, label=\"ROC curve (area = %0.2f)\" % roc_auc,)\n",
        "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "    if fpr_tpr is not None:\n",
        "        plt.plot(fpr_tpr[0], fpr_tpr[1], color=\"green\", lw = 3, marker='x')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    if filename is None:\n",
        "        filename = \"\"\n",
        "    plt.title(f'{filename[10:-4]} ROC Curve')     # test_data/test_1012.csv --> test_1012\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    if directory is not None:\n",
        "        # save plot to directory\n",
        "        f = os.path.join(directory, filename[10:-4])\n",
        "        plt.savefig(f'{f}-roc.png')\n",
        "\n",
        "    # Need to polish this\n",
        "\n",
        "\n",
        "\n",
        "def confusion_matrix_display(y_test, y_pred, filename=None, directory=None):\n",
        "    # inputs: actual labels & prediction labels\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)     # labels=clf.classes_\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix = cm)     # display_labels=clf.classes_\n",
        "    disp.plot()\n",
        "    if filename is None:\n",
        "        filename = \"\"\n",
        "    plt.title(f'{filename[10:-4]} Confusion Matrix')     # test_data/test_1012.csv --> test_1012\n",
        "    plt.show()\n",
        "\n",
        "    if directory is not None:\n",
        "        # save plot to directory\n",
        "        f = os.path.join(directory, filename[10:-4])\n",
        "        plt.savefig(f'{f}-confmat.png')\n",
        "\n",
        "    return tn, fp, fn, tp\n",
        "\n",
        "\n",
        "\n",
        "def prec_rec_accu(y_test, y_pred):\n",
        "    # y_test & y_pred need to be 1-D arrays\n",
        "\n",
        "    precision3 = precision_score(y_test, y_pred)\n",
        "    recall3 = recall_score(y_test, y_pred)\n",
        "    accuracy3 = (y_pred3==y_test.Class).sum()/len(y_pred3)\n",
        "    print('For test data: ')\n",
        "    print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
        "        round(precision3, 3), round(recall3, 3), round(accuracy3, 3)))\n",
        "    \n",
        "    return precision3, recall3, accuracy3"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ccb01838363a4066a44a81992df4c06a",
        "source_hash": "abf12822",
        "is_code_hidden": true,
        "execution_start": 1674080104108,
        "execution_millis": 16574,
        "is_output_hidden": true,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "udY2E0sFZIqU",
        "outputId": "fc519e2b-032d-4796-9ca5-7814fbc5188d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Practice\n",
        "#### v. 20230118"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "acbdd5e51fa346b2b141d7dcf4ba0274",
        "deepnote_cell_type": "markdown",
        "id": "JRkT4Q-yZIqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip3 install torch torchvision torchaudio     # for PyTorch without GPU, just CPU\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d680c6cc343e44dda5236360ff9ce245",
        "source_hash": "a40f784d",
        "execution_start": 1674080120693,
        "execution_millis": 11,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "vKI5w-BMZIqc"
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U"
      ],
      "metadata": {
        "id": "I7P3DUOpgV7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d157115-f147-4916-e944-237d35023c42"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0.dev0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU can be detected\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()              # '/device:GPU:0' means GPU is enabled\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eWAtNCmrzso",
        "outputId": "06da9425-e761-4674-9ba6-ed7c0b15911f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# torch.cuda.is_available = lambda : False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1KyaineWiqgA",
        "outputId": "80b34946-1719-455c-83ae-292a51962ca2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo            # check memory resources available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf6uQarosHGv",
        "outputId": "b87b5522-c8af-4741-8b56-868378dce592"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13297192 kB\n",
            "MemFree:          565624 kB\n",
            "MemAvailable:    7973144 kB\n",
            "Buffers:          362748 kB\n",
            "Cached:          7137612 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1187008 kB\n",
            "Inactive:       11033440 kB\n",
            "Active(anon):        916 kB\n",
            "Inactive(anon):  4708412 kB\n",
            "Active(file):    1186092 kB\n",
            "Inactive(file):  6325028 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1552 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       4720160 kB\n",
            "Mapped:          1103328 kB\n",
            "Shmem:             15584 kB\n",
            "KReclaimable:     222452 kB\n",
            "Slab:             277096 kB\n",
            "SReclaimable:     222452 kB\n",
            "SUnreclaim:        54644 kB\n",
            "KernelStack:        5184 kB\n",
            "PageTables:        41860 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648596 kB\n",
            "Committed_AS:    6739124 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       53756 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1336 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      342848 kB\n",
            "DirectMap2M:    10139648 kB\n",
            "DirectMap1G:     5242880 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qu9kfdGl1Vv2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "SCmAhc2i0JDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0ea7ee-09f2-4dc2-be4c-ccbd2da1cf2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-19 21:22:55--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27264 (27K) [text/plain]\n",
            "Saving to: ‘run_glue.py.1’\n",
            "\n",
            "run_glue.py.1       100%[===================>]  26.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-19 21:22:55 (77.9 MB/s) - ‘run_glue.py.1’ saved [27264/27264]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# install wandb for tracking data on dashboard\n",
        "!pip install datasets wandb evaluate -qU\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gGvsX_9j0JDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66226b34-fbe5-4ffb-b479-6429e9375988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# the run_glue.py script requires transformers dev\n",
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "of5C4XID0JDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7456ad0e-1a13-43c8-e3e7-c01c4ca7abc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# log in to have data synced to account\n",
        "# wandb.login()\n",
        "\n",
        "# log every trained model\n",
        "%env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://github.com/PradipNichite/Youtube-Tutorials/blob/main/FineTune_BERT_Model_Youtube.ipynb\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df22 = pd.read_csv('/S22_train20221011.csv', sep='\\t', index_col=0).drop_duplicates()\n",
        "\n",
        "# repair rows where values are shifted by 1 column\n",
        "shift_rows = df22.loc[df22[df22.Class.apply(lambda x: x == 'None')].index]   # rows where columns shifted to left\n",
        "shift_values = shift_rows[df22.columns[1:-1]]\n",
        "shift_rows[df22.columns[2:]] = shift_rows[df22.columns[1:-1]]\n",
        "shift_rows.Content = ''\n",
        "df22.loc[df22[df22.Class.apply(lambda x: x == 'None')].index] = shift_rows\n",
        "\n",
        "# filter training data to desired dates\n",
        "df22 = df22[df22.Date.apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').date() > datetime(2022,2,21).date())]\n",
        "\n",
        "# For class imbalance, use roughly same ratio of R & N\n",
        "######################################################### BERT doesn't need class imbalance addressed\n",
        "# df22 = pd.concat([df22[df22.Class=='R'], df22[df22.Class=='N'].iloc[::3, :]])\n",
        "\n",
        "# combine title & content as text22, clean the text, then combine it with labels to a single df  \n",
        "text22, classes22 = data_split(df22)\n",
        "df22, classes22 = drop_dupe_text(text22, classes22)\n",
        "\n",
        "# Preprocessing & data cleaning not required; BERT uses all info in sentence (punctuation, stopwords, etc)   \n",
        "df22['Class'] = classes22['Class']\n",
        "\n",
        "df22.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################ DELETE THIS LINE LATER (purpose: reduce data to reduce training time to test features)\n",
        "# df22 = df22.sample(frac=0.01, random_state=5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9f955299a3e54a1aaebfc738a20d1320",
        "source_hash": "76f0006d",
        "execution_start": 1674080120705,
        "execution_millis": 808,
        "is_output_hidden": false,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "k6xcfS07ZIqd",
        "outputId": "42782272-c73c-4523-c0d4-169a2bb7ce00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Text  Class\n",
              "452  Zfold 3 or S22 ultra Trying to decide between ...      0\n",
              "453  S22 video cam Anyone tried out the video camer...      0\n",
              "454  Thinking about trading my S21Ultra for S22+ Ev...      0\n",
              "455  S21 Ultra vs S22+ Both phones are currently at...      0\n",
              "456  S21 or S22 Base/Standard Model Hey All,\\n\\nLoo...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>Zfold 3 or S22 ultra Trying to decide between ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>S22 video cam Anyone tried out the video camer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>Thinking about trading my S21Ultra for S22+ Ev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>S21 Ultra vs S22+ Both phones are currently at...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>S21 or S22 Base/Standard Model Hey All,\\n\\nLoo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc39f7c5-72a2-41ca-ab31-859fd8aba8ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "execution_count": 65
    },
    {
      "cell_type": "code",
      "source": [
        "df22['Class'].value_counts()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ddbfd30c829a40c9af60fd8fc4ad8bb3",
        "source_hash": "fda411fd",
        "execution_start": 1674080121523,
        "execution_millis": 6,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJtMeTRwZIqe",
        "outputId": "a060842e-c072-49d4-bb23-7dc48a50c7ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    13926\n",
              "1     3658\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "execution_count": 66
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d968ff4c82ea4fe89fdeecd8ad261bda",
        "source_hash": "65934339",
        "execution_start": 1674080121543,
        "execution_millis": 5340,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk_eN8Q0ZIqe",
        "outputId": "cac16cdf-0165-4528-bdfa-d929b4ae33c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 67
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "506970be01814296ad84c7c9f3312165",
        "source_hash": "d991cab6",
        "execution_start": 1674080126876,
        "execution_millis": 88,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxeRDLYZIqf",
        "outputId": "0ae8617a-460a-47b0-e9ca-4943e8ea731b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "execution_count": 68
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.to( torch.device('cuda') )     # need NVIDIA driver for 'cuda'; currently have AMD on work laptop\n",
        "# model = model.to('cpu')         # train on CPU\n",
        "\n",
        "model = model.to('cuda')          # or  model.cuda()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "abaddecf0f7a4867b3088265ded4cec5",
        "source_hash": "ff8dd7cb",
        "execution_start": 1674080126980,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "65yDwWirZIqf"
      },
      "outputs": [],
      "execution_count": 69
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data = [\"This is possibly the worst battery I have ever seen on a mobile device\",\n",
        "            \"How is my device running so smoothly?\"]\n",
        "tokenizer(test_data, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "cbadffae0dd44bbbb994e70f20146772",
        "source_hash": "6c516043",
        "execution_start": 1674080126981,
        "execution_millis": 100,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z6XRhJgZIqg",
        "outputId": "e784b6b3-b53d-48ad-b0e9-28c20867749a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2023, 2003, 4298, 1996, 5409, 6046, 1045, 2031, 2412, 2464, 2006, 1037, 4684, 5080, 102], [101, 2129, 2003, 2026, 5080, 2770, 2061, 15299, 1029, 102, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "execution_count": 70
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df22[\"Text\"])\n",
        "y = list(df22[\"Class\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "af668836fd5341ac9016a845ebe79057",
        "source_hash": "25d321c9",
        "execution_start": 1674080127028,
        "execution_millis": 27370,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "o-G23j4EZIqg"
      },
      "outputs": [],
      "execution_count": 71
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized.keys()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "0ddc2b86e99d47f49d560a7a4a7427a9",
        "source_hash": "882ded45",
        "execution_start": 1674080154402,
        "execution_millis": 14,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2IkScN2ZIqh",
        "outputId": "658c96eb-981c-46ff-b843-23812171bdcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "execution_count": 72
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tokenized['attention_mask'][0])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "31306b38d6424983b8ec35e35b89d5d5",
        "source_hash": "c5b8c3f4",
        "execution_start": 1674080169475,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn6O2T8lZIqh",
        "outputId": "4a4d8b82-c32a-4f18-c100-0aca5c3b639a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "execution_count": 73
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train),len(X_val)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "c20d101dd6e84dff850d5446d87227b5",
        "source_hash": "1851768b",
        "execution_start": 1674080189480,
        "execution_millis": 0,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPVhi1tNZIqi",
        "outputId": "daec6f46-ffe4-4449-f836-25cdadd4ff83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14067, 3517)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "execution_count": 74
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch dataset\n",
        "class VOC_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "785f8f506f724850be7cdd073ff8bfd4",
        "source_hash": "3b060da6",
        "execution_start": 1674080232215,
        "execution_millis": 12,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "OC-jBK8SZIqi"
      },
      "outputs": [],
      "execution_count": 75
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOC_Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = VOC_Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9b6f589cb6274e459cf4b21ca9416ac7",
        "source_hash": "78f426a3",
        "execution_start": 1674080252981,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "0J6cyoT6ZIqi"
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "e74bd73ccb5e49869e5db0dc8d5da4db",
        "source_hash": "a1b8da62",
        "execution_start": 1674080260113,
        "execution_millis": 47,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT0-A0GyZIqj",
        "outputId": "59b9b6da-c31e-432c-eaeb-ee786d1efe3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  1055, 19317, 11087,  2417,  7262,  3475,  1005,  1056,  1012,\n",
              "          1012,  1012,  2417,  1029,  2633,  2288,  2026,  1055, 19317, 11087,\n",
              "          5359,  2651,  1998,  2009,  1005,  1055,  2025,  2130,  2485,  2000,\n",
              "          2417,  1012,  2009,  1005,  1055, 11034,  2012,  2190,  1012,  2428,\n",
              "          1010,  2428,  9364,  1012,   102,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "execution_count": 77
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(m):\n",
        "    print(type(m))\n",
        "    pred, labels = m\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "     "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d89ebde51e854f5c9bfb45c57a0b8eb2",
        "source_hash": "2986a0e5",
        "execution_start": 1674080319332,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "ItJjuFt_ZIqj"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Trainer\n",
        "args = TrainingArguments(\n",
        "    report_to = 'wandb',                     # enable logging to W&B\n",
        "    output_dir=\"output\",                     # output directory\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8\n",
        "    # overwrite_output_dir = True,\n",
        "    # evaluation_strategy = 'steps',          # check evaluation metrics at each epoch\n",
        "    # learning_rate = 5e-5,                   # we can customize learning rate\n",
        "    # max_steps = 30000,\n",
        "    # logging_steps = 100,                    # we will log every 100 steps\n",
        "    # eval_steps = 5000,                      # we will perform evaluation every 500 steps\n",
        "    # save_steps = 10000,\n",
        "    # load_best_model_at_end = True,\n",
        "    # metric_for_best_model = 'accuracy',\n",
        "    # run_name = 'custom_training'            # name of the W&B run\n",
        "\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,            # for padding batched data\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "f95f543b3daa425ebecc01270b25bf91",
        "source_hash": "223c3ba0",
        "execution_start": 1674080330040,
        "execution_millis": 145,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFYxNIctZIqj",
        "outputId": "a99358e2-a177-4b55-80a6-924e7147a61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "start = timer()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "end = timer()\n",
        "print(\"%4f seconds, %4f minutes elapsed\" % (float(end-start), float((end-start)/60)))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8185c9ee39774fcba9200e83819fce3f",
        "source_hash": "c4a351e7",
        "execution_start": 1674080563381,
        "execution_millis": 17834,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "8NO7NW3bZIqk",
        "outputId": "9f1a5cb0-8115-4662-d66e-51844db6af2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 14067\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1759\n",
            "  Number of trainable parameters = 109483778\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1759' max='1759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1759/1759 21:47, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.370800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.307900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.279600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-1000\n",
            "Configuration saved in output/checkpoint-1000/config.json\n",
            "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-1500\n",
            "Configuration saved in output/checkpoint-1500/config.json\n",
            "Model weights saved in output/checkpoint-1500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /tmp/tmp7qc0kwc5\n",
            "Configuration saved in /tmp/tmp7qc0kwc5/config.json\n",
            "Model weights saved in /tmp/tmp7qc0kwc5/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1308.139700 seconds, 21.802328 minutes elapsed\n"
          ]
        }
      ],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "97a062b8225e4125971486d915e3ac86",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "4L3oPcUvZIqk",
        "outputId": "f4e3d3c5-348e-47a4-deb4-49b0d28c5b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3517\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [440/440 01:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.trainer_utils.EvalPrediction'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2499202936887741,\n",
              " 'eval_accuracy': 0.9033266988911004,\n",
              " 'eval_precision': 0.7768361581920904,\n",
              " 'eval_recall': 0.7513661202185792,\n",
              " 'eval_f1': 0.763888888888889,\n",
              " 'eval_runtime': 112.6355,\n",
              " 'eval_samples_per_second': 31.225,\n",
              " 'eval_steps_per_second': 3.906,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "2920442657d045288b468403b8e7ce45",
        "deepnote_cell_type": "code",
        "id": "ee-3alVdZIqk"
      },
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Super charging is working very well.\"\n",
        "# text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "print(outputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)    # also gelu(), silu()\n",
        "print(predictions)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "b95d7749d3074a20bdfa3cdc432b149e",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndgwa_feZIql",
        "outputId": "1c11fb14-08bc-4ca0-ad39-947b57c2b98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8727, -1.0109]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "tensor([[ 0.6155, -0.2697]], device='cuda:0', grad_fn=<SiluBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.61548567, -0.26971212]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "execution_count": 105
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('BertPractice')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehJCv_jKWoge",
        "outputId": "83ef3ca0-596f-4572-b086-b0661db066d6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to BertPractice\n",
            "Configuration saved in BertPractice/config.json\n",
            "Model weights saved in BertPractice/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.save_model('/content/drive/MyDrive/Youtube Tutorials/toxic')\n",
        "# model_2 = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Youtube Tutorials/toxic\")\n",
        "# model_2.to('cuda')"
      ],
      "metadata": {
        "id": "FDIfAtXeWqBP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = BertForSequenceClassification.from_pretrained('BertPractice')\n",
        "model_2.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9af__siKWrvn",
        "outputId": "27483ca9-7079-409b-9bd7-fde1520935a3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file BertPractice/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file BertPractice/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BertPractice.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Super charging is working very well.\"\n",
        "text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model_2(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "53e74eee144d445da85927276d7daff3",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf4WU--hZIql",
        "outputId": "04c7c74f-ea28-4624-ead8-b3b0798c6251"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09049978, 0.90950024]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "execution_count": 115
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#today's VOC\n",
        "# import file and combine title & content\n",
        "voctoday = pd.read_csv('/0119.csv', sep='\\t', index_col=None).drop_duplicates()\n",
        "voctoday['title'] = voctoday['title'].astype(str) + \" \" + voctoday['content'].astype(str)\n",
        "voctoday = voctoday[['title', 'class']]\n",
        "\n",
        "voclist = list(voctoday['title'])\n",
        "predlist = []\n",
        "\n",
        "for i in range(len(voclist)):\n",
        "  inputs = tokenizer(voclist[i], padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "  outputs = model_2(**inputs)\n",
        "  predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "  predictions = predictions.cpu().detach().numpy()\n",
        "  predlist.append(predictions)\n",
        "\n",
        "organizedzip = zip([x[:25] for x in voclist],\n",
        "                   predlist,\n",
        "                   voctoday['class'])\n",
        "    \n",
        "# results as voc text, predictions, and actual value\n",
        "print(list(organizedzip))\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6093bde4694f46c195c95d0798e529cb",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvNon4aUZIql",
        "outputId": "35a8d080-3cbb-4a04-a035-d9de5f5b2ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('2nd January update I just', array([[0.9971807 , 0.00281931]], dtype=float32), 'N'), ('No Questions just wanted ', array([[0.9981193 , 0.00188064]], dtype=float32), 'N'), ('S22u vs S23u Having time ', array([[0.9957015 , 0.00429845]], dtype=float32), 'N'), ('No more lag and stutter a', array([[0.7561109, 0.2438891]], dtype=float32), 'N'), ('Qualcomm Bluetooth Codecs', array([[0.99762386, 0.00237617]], dtype=float32), 'N'), ('Sound Issues Hey everyone', array([[0.07707566, 0.92292434]], dtype=float32), 'R'), ('Samsung Leather Case vs O', array([[0.9981981, 0.0018019]], dtype=float32), 'N'), ('Weather widget help nan', array([[0.97075576, 0.02924431]], dtype=float32), 'R'), ('battery concern I can squ', array([[0.9247212 , 0.07527879]], dtype=float32), 'R'), ('S22 Ultra Camera Issued H', array([[0.06688055, 0.9331195 ]], dtype=float32), 'R'), ('Single Take Functionality', array([[0.97552943, 0.02447058]], dtype=float32), 'N'), ('So I already had the Janu', array([[0.9965773 , 0.00342264]], dtype=float32), 'N'), ('S22 Ultra not super Fast ', array([[0.09622952, 0.9037705 ]], dtype=float32), 'R'), ('Odd camera / video issue ', array([[0.06867576, 0.93132424]], dtype=float32), 'R'), ('Which variant should I pi', array([[0.99741805, 0.00258196]], dtype=float32), 'N'), ('Next best thing to ROOT o', array([[0.9976853 , 0.00231465]], dtype=float32), 'N'), ('Samsung Pass So I know mo', array([[0.97717094, 0.0228291 ]], dtype=float32), 'N'), ('S22+ drops to its lowest ', array([[0.94260883, 0.05739109]], dtype=float32), 'N'), ('Should I trade my s22 for', array([[0.99857163, 0.00142838]], dtype=float32), 'N'), ('Galaxy S22 Ultra live dem', array([[0.99846256, 0.00153746]], dtype=float32), 'N'), ('Planning to pre-order S23', array([[0.998553, 0.001447]], dtype=float32), 'N'), ('Am I the only one who thi', array([[0.8282212 , 0.17177877]], dtype=float32), 'N'), ('Calls not working on car ', array([[0.06585397, 0.93414605]], dtype=float32), 'R'), ('US S22+ only one physical', array([[0.99576265, 0.00423735]], dtype=float32), 'N'), ('Galaxy S22 battery life f', array([[0.98432595, 0.01567405]], dtype=float32), 'N'), ('i am using a s22 and i am', array([[0.9980702 , 0.00192984]], dtype=float32), 'N'), ('Which is better: Samsung ', array([[0.9979746 , 0.00202539]], dtype=float32), 'N'), ('S22 exynos 128 for 600 € ', array([[0.9985879 , 0.00141204]], dtype=float32), 'N'), ('S22 ultra vs s23 ultra! S', array([[0.99852437, 0.00147562]], dtype=float32), 'N'), ('Return the S22+? I recent', array([[0.9986027 , 0.00139738]], dtype=float32), 'N'), ('My dilemma: S21 FE or S22', array([[0.99724424, 0.00275579]], dtype=float32), 'N'), ('No 4K 120fps but I found ', array([[0.9933248 , 0.00667518]], dtype=float32), 'N'), ('I deleted some text messa', array([[0.99478084, 0.00521919]], dtype=float32), 'N'), ('Group messages I just rec', array([[0.11345708, 0.8865429 ]], dtype=float32), 'R'), ('Block Unknown Numbers Not', array([[0.07255138, 0.92744863]], dtype=float32), 'R'), ('Notifications glitch? Aft', array([[0.07246736, 0.9275326 ]], dtype=float32), 'R'), ('Black and White Somehow e', array([[0.14287566, 0.8571243 ]], dtype=float32), 'R'), ('Multiple Voicemail Notifi', array([[0.542721  , 0.45727903]], dtype=float32), 'R'), ('Angry The display of my S', array([[0.17455518, 0.8254448 ]], dtype=float32), 'R'), ('Backspace Why does my bac', array([[0.8713595 , 0.12864044]], dtype=float32), 'N'), ('Multiple Notification sou', array([[0.9725605 , 0.02743946]], dtype=float32), 'R'), (\"Don't have the us Galaxy \", array([[0.99168056, 0.00831943]], dtype=float32), 'N'), ('Fast charging I have s22+', array([[0.07091352, 0.9290865 ]], dtype=float32), 'R')]\n"
          ]
        }
      ],
      "execution_count": 140
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "8207dc085d8b42718086312e08437452",
        "deepnote_cell_type": "code",
        "id": "5Bw4LKQzZIqm"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "5aeac4c1c9b34e4b9afe24f40e1d3c27",
        "source_hash": "24acd7c3",
        "is_code_hidden": true,
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "XHyZQQDLZIqm"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "501fe0946abe4e6398eb6a364a652e3c",
        "source_hash": "b623e53d",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "HOzIXC_iZIqm"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e5caba9f-cd36-4d50-aaa3-2cf59957a2f4' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "llB-FWxEZIqn"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {},
    "orig_nbformat": 2,
    "deepnote_notebook_id": "99baf882d48d4fa4b40b67d8bd9057bf",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}