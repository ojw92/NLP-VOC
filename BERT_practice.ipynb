{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojw92/NLP-for-Text-Classification/blob/main/BERT_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "d2b3fe256b094e82a87b624b50b7af86",
        "deepnote_cell_type": "markdown",
        "id": "_u716cCIZIqP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8M_IjgNzPa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Practice\n",
        "#### v. 20230118"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "acbdd5e51fa346b2b141d7dcf4ba0274",
        "deepnote_cell_type": "markdown",
        "id": "JRkT4Q-yZIqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip3 install torch torchvision torchaudio     # for PyTorch without GPU, just CPU\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d680c6cc343e44dda5236360ff9ce245",
        "source_hash": "a40f784d",
        "execution_start": 1674080120693,
        "execution_millis": 11,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "vKI5w-BMZIqc"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U"
      ],
      "metadata": {
        "id": "I7P3DUOpgV7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc49a4a-772a-4612-bc65-8d0d1c389ba0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.27.0.dev0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU can be detected\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()              # '/device:GPU:0' means GPU is enabled\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eWAtNCmrzso",
        "outputId": "96125e3d-62c1-4316-967f-03ed95b0b07f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# torch.cuda.is_available = lambda : False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "1KyaineWiqgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca7746f1-5cd9-44ed-efb3-77612b5a61a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo            # check memory resources available"
      ],
      "metadata": {
        "id": "Nf6uQarosHGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495b5607-8f78-4019-fefd-7ca0e96fb6f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13297200 kB\n",
            "MemFree:         3878884 kB\n",
            "MemAvailable:   10242096 kB\n",
            "Buffers:          360512 kB\n",
            "Cached:          6130944 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           966772 kB\n",
            "Inactive:        8010188 kB\n",
            "Active(anon):        916 kB\n",
            "Inactive(anon):  2468732 kB\n",
            "Active(file):     965856 kB\n",
            "Inactive(file):  5541456 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1188 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       2485584 kB\n",
            "Mapped:           964304 kB\n",
            "Shmem:             13512 kB\n",
            "KReclaimable:     181824 kB\n",
            "Slab:             228948 kB\n",
            "SReclaimable:     181824 kB\n",
            "SUnreclaim:        47124 kB\n",
            "KernelStack:        4672 kB\n",
            "PageTables:        14496 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648600 kB\n",
            "Committed_AS:    5075280 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       58420 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1344 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      400192 kB\n",
            "DirectMap2M:    11130880 kB\n",
            "DirectMap1G:     4194304 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qu9kfdGl1Vv2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SCmAhc2i0JDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef2ffb3-8c6b-4642-aad9-7a190433c794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 05:29:42--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27264 (27K) [text/plain]\n",
            "Saving to: ‘run_glue.py.1’\n",
            "\n",
            "run_glue.py.1       100%[===================>]  26.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 05:29:42 (88.8 MB/s) - ‘run_glue.py.1’ saved [27264/27264]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# install wandb for tracking data on dashboard\n",
        "!pip install datasets wandb evaluate -qU\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gGvsX_9j0JDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2272830-20f0-432d-d497-06d4ec41df6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# the run_glue.py script requires transformers dev\n",
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "of5C4XID0JDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f646fc-f673-4c28-f7ec-df767e998aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mojw92\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# log in to have data synced to account\n",
        "wandb.login()\n",
        "\n",
        "# log every trained model\n",
        "%env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://github.com/PradipNichite/Youtube-Tutorials/blob/main/FineTune_BERT_Model_Youtube.ipynb\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# filter training data to desired dates (after 2022.2.22)\n",
        "df = pd.read_csv('/S22_total.csv', index_col=0).drop_duplicates()\n",
        "\n",
        "# filter training data to desired dates\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "df = df[df.Date.apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date() > datetime(2022,2,21).date())]\n",
        "\n",
        "# For class imbalance, use roughly same ratio of R & N\n",
        "# BERT doesn't need class imbalance addressed\n",
        "# df = pd.concat([df[df.Class=='R'], df[df.Class=='N'].iloc[::3, :]])\n",
        "\n",
        "# Reduce data to reduce training time to test features\n",
        "# df22 = df22.sample(frac=0.01, random_state=5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9f955299a3e54a1aaebfc738a20d1320",
        "source_hash": "76f0006d",
        "execution_start": 1674080120705,
        "execution_millis": 808,
        "is_output_hidden": false,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "k6xcfS07ZIqd"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Title + Content concatenator\n",
        "from timeit import default_timer as timer\n",
        "import re\n",
        "\n",
        "def data_concat(df22, R_known=True):\n",
        "\n",
        "    # Split the input dataframe into Text (Title + Contents) and Classes dataframes\n",
        "    # input must have 3 columns of string entries (Title, Contents, and Classes)\n",
        "\n",
        "    # check if every row entry of each column is string type (some are NaN, so no)\n",
        "    # print(df22.applymap(lambda x : type(x).__name__).eq({'Title': 'str', 'Content': 'str', 'Class':'str'}))\n",
        "\n",
        "    # convert NaN to empty strings (NaN -> str)\n",
        "        # df22.apply(str) converts all columns to str, as well\n",
        "    df22 = df22.replace(float('nan'), '', regex=True)\n",
        "\n",
        "    # concatenate strings of title & content with a \" \" in between (1 body of text)\n",
        "    df22['Text'] = df22['Title'] + \" \" + df22['Content']      # slicing DataFrame via .iloc[:,0] makes it a Series\n",
        "    df22 = df22.loc[: , ['Text', 'Class']]    # so initialize it as a DataFrame. pd.DataFrame(some_Series) works\n",
        "\n",
        "    if R_known == True:\n",
        "    # R, r, YR = 1;     N, n, YN = 0\n",
        "        R_cases = re.compile('R|YR', re.IGNORECASE)\n",
        "        N_cases = re.compile('N|YN', re.IGNORECASE)\n",
        "        df22['Class'] = df22['Class'].replace(to_replace=R_cases, value=1)\n",
        "        df22['Class'] = df22['Class'].replace(to_replace=N_cases, value=0)\n",
        "    else:\n",
        "        # R_known == False; prepping not yet classified data\n",
        "        Y_N_cases = re.compile('Y|N', re.IGNORECASE)\n",
        "        df22['Class'] = df22['Class'].replace(to_replace=Y_N_cases, value=0)     # all N's for simplicity\n",
        "\n",
        "    df22['Class'] = df22['Class'].astype('int32')\n",
        "\n",
        "\n",
        "    return df22\n"
      ],
      "metadata": {
        "id": "I94k-OsHcdmM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine title & content as text22, clean the text, then combine it with labels to a single df  \n",
        "df = data_concat(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Nh1gY_I2c-aJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "11841e95-ac05-449f-b440-6b6ecbcea605"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Text  Class\n",
              "452  Zfold 3 or S22 ultra Trying to decide between ...      0\n",
              "453  S22 video cam Anyone tried out the video camer...      0\n",
              "454  Thinking about trading my S21Ultra for S22+ Ev...      0\n",
              "455  S21 Ultra vs S22+ Both phones are currently at...      0\n",
              "456  S21 or S22 Base/Standard Model Hey All,\\n\\nLoo...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8192e769-3556-45c2-b05b-c0dc8fca4fb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>Zfold 3 or S22 ultra Trying to decide between ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>S22 video cam Anyone tried out the video camer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>Thinking about trading my S21Ultra for S22+ Ev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>S21 Ultra vs S22+ Both phones are currently at...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>S21 or S22 Base/Standard Model Hey All,\\n\\nLoo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8192e769-3556-45c2-b05b-c0dc8fca4fb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8192e769-3556-45c2-b05b-c0dc8fca4fb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8192e769-3556-45c2-b05b-c0dc8fca4fb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ddbfd30c829a40c9af60fd8fc4ad8bb3",
        "source_hash": "fda411fd",
        "execution_start": 1674080121523,
        "execution_millis": 6,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "kJtMeTRwZIqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336144c7-20f5-4557-ad56-54f435fb9c35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    17752\n",
              "1     5218\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d968ff4c82ea4fe89fdeecd8ad261bda",
        "source_hash": "65934339",
        "execution_start": 1674080121543,
        "execution_millis": 5340,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "jk_eN8Q0ZIqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9116131-921e-4244-8b88-6906c3747776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "506970be01814296ad84c7c9f3312165",
        "source_hash": "d991cab6",
        "execution_start": 1674080126876,
        "execution_millis": 88,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "FYxeRDLYZIqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684e49a9-9001-4f3c-ddb9-6089500046ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.to( torch.device('cuda') )     # need NVIDIA driver for 'cuda'; currently have AMD on work laptop\n",
        "# model = model.to('cpu')         # train on CPU\n",
        "\n",
        "model = model.to('cuda')          # or  model.cuda()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "abaddecf0f7a4867b3088265ded4cec5",
        "source_hash": "ff8dd7cb",
        "execution_start": 1674080126980,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "65yDwWirZIqf"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data = [\"This is possibly the worst battery I have ever seen on a mobile device\",\n",
        "            \"How is my device running so smoothly?\"]\n",
        "tokenizer(test_data, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "cbadffae0dd44bbbb994e70f20146772",
        "source_hash": "6c516043",
        "execution_start": 1674080126981,
        "execution_millis": 100,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "-z6XRhJgZIqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1b441b-2722-4166-8313-d38c6add1ded"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2023, 2003, 4298, 1996, 5409, 6046, 1045, 2031, 2412, 2464, 2006, 1037, 4684, 5080, 102], [101, 2129, 2003, 2026, 5080, 2770, 2061, 15299, 1029, 102, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df[\"Text\"])\n",
        "y = list(df[\"Class\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "af668836fd5341ac9016a845ebe79057",
        "source_hash": "25d321c9",
        "execution_start": 1674080127028,
        "execution_millis": 27370,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "o-G23j4EZIqg"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized.keys()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "0ddc2b86e99d47f49d560a7a4a7427a9",
        "source_hash": "882ded45",
        "execution_start": 1674080154402,
        "execution_millis": 14,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "O2IkScN2ZIqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd86db5-6129-4ec9-d27b-52fec90aeed0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tokenized['attention_mask'][0])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "31306b38d6424983b8ec35e35b89d5d5",
        "source_hash": "c5b8c3f4",
        "execution_start": 1674080169475,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "yn6O2T8lZIqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4040c060-aa46-4af6-f23d-dcf75b1ca9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train),len(X_val)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "c20d101dd6e84dff850d5446d87227b5",
        "source_hash": "1851768b",
        "execution_start": 1674080189480,
        "execution_millis": 0,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "WPVhi1tNZIqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d0a3ca-9df3-4f23-beea-da4270fd1cf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18376, 4594)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch dataset\n",
        "class VOC_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "785f8f506f724850be7cdd073ff8bfd4",
        "source_hash": "3b060da6",
        "execution_start": 1674080232215,
        "execution_millis": 12,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "OC-jBK8SZIqi"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOC_Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = VOC_Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9b6f589cb6274e459cf4b21ca9416ac7",
        "source_hash": "78f426a3",
        "execution_start": 1674080252981,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "0J6cyoT6ZIqi"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "e74bd73ccb5e49869e5db0dc8d5da4db",
        "source_hash": "a1b8da62",
        "execution_start": 1674080260113,
        "execution_millis": 47,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "WT0-A0GyZIqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3da7950-dbdc-4b9c-c930-ef4e6f2d06df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  3435, 13003,  6762,  2044,  2261,  3823,  1045,  2699,  2007,\n",
              "          2116,  2367,  3715,  2099,  1998, 15196,  2021,  2053,  2224,  1010,\n",
              "          2009,  4627,  2007,  3435, 13003,  2021,  3402,  2044,  1037,  2096,\n",
              "          3632,  2067,  2000,  3671,  3177,  1010,  2043,  1045,  2735,  2125,\n",
              "          3435, 13003,  1045,  2131,  1037,  3769,  2039,  2000,  2735,  2009,\n",
              "          2006,  2004,  2092,  1012,  2026,  2564,  2038, 13433,  3597,  1060,\n",
              "          2475,  2029,  6753, 22851,  1010,  2005,  2014,  2168,  3715,  2099,\n",
              "          2053,  3277,  1012, 10086,  1024,  1045,  7718,  2007, 16222,  2226,\n",
              "          6046,  1010,  2009,  4627,  2007, 11910, 25687,  2021,  3632,  2067,\n",
              "          2000, 10347, 25687,  2823,  2130,  2625,  2084,  6694,   102,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(1)}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(m):\n",
        "    print(type(m))\n",
        "    pred, labels = m\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "     "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d89ebde51e854f5c9bfb45c57a0b8eb2",
        "source_hash": "2986a0e5",
        "execution_start": 1674080319332,
        "execution_millis": 17,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "ItJjuFt_ZIqj"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Trainer\n",
        "args = TrainingArguments(\n",
        "    report_to = 'wandb',                     # enable logging to W&B\n",
        "    output_dir=\"output\",                     # output directory\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8\n",
        "    # overwrite_output_dir = True,\n",
        "    # evaluation_strategy = 'steps',          # check evaluation metrics at each epoch\n",
        "    # learning_rate = 5e-5,                   # we can customize learning rate\n",
        "    # max_steps = 30000,\n",
        "    # logging_steps = 100,                    # we will log every 100 steps\n",
        "    # eval_steps = 5000,                      # we will perform evaluation every 500 steps\n",
        "    # save_steps = 10000,\n",
        "    # load_best_model_at_end = True,\n",
        "    # metric_for_best_model = 'accuracy',\n",
        "    # run_name = 'custom_training'            # name of the W&B run\n",
        "\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,            # for padding batched data\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "f95f543b3daa425ebecc01270b25bf91",
        "source_hash": "223c3ba0",
        "execution_start": 1674080330040,
        "execution_millis": 145,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "CFYxNIctZIqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc45203-a659-4986-cb94-9ee328273080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/facebookresearch/fairseq/issues/1933\n",
        "# https://huggingface.co/spaces/OFA-Sys/OFA-Generic_Interface/blob/8fc1d8aafce5821301443744696303bac6227f52/fairseq/examples/roberta/commonsense_qa/README.md\n",
        "\n",
        "# PyTorch fairseq\n",
        "\n",
        "MAX_UPDATES=2300      # Number of training steps, where   training step = training set / batch size. Originally 3000\n",
        "WARMUP_UPDATES=150    # Linearly increase LR over this many steps\n",
        "MAX_EPOCH=2           # Number of training epochs.\n",
        "LR=1e-06              # Peak LR for fixed LR scheduler. 1e-05 default; try 1e-06 as initial LR\n",
        "NUM_CLASSES=2\n",
        "MAX_SENTENCES=8       # Batch size per GPU.\n",
        "UPDATE_FREQ=32        # Accumulate gradients to simulate training on 8 GPUs. \n",
        "DATA_DIR='VOC_final_output'\n",
        "ROBERTA_PATH='/SiERoBERT_large/model.pt'\n",
        "\n",
        "! CUDA_VISIBLE_DEVICES=0 fairseq-train $DATA_DIR --ddp-backend=no_c10d \\\n",
        "  --restore-file $ROBERTA_PATH \\\n",
        "  --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "  --no-epoch-checkpoints --no-last-checkpoints --no-save-optimizer-state \\\n",
        "  #--best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
        "  --task sentence_ranking \\\n",
        "  --num-classes $NUM_CLASSES \\\n",
        "  --init-token 0 --separator-token 2 \\\n",
        "  --max-option-length 128 \\\n",
        "  --max-positions 512 \\\n",
        "  --truncate-sequence \\\n",
        "  --arch roberta_large \\\n",
        "  --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
        "  --criterion sentence_ranking \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.98)' --adam-eps 1e-06 \\\n",
        "  --clip-norm 0.0 \\\n",
        "  --lr-scheduler fixed --lr $LR \\\n",
        "  --warmup-updates $WARMUP_UPDATES --total-num-update $MAX_UPDATES \\\n",
        "  --memory-efficient-fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \\\n",
        "  --batch-size $MAX_SENTENCES \\\n",
        "  --required-batch-size-multiple 1 \\\n",
        "  --update-freq $UPDATE_FREQ \\\n",
        "  --max-epoch $MAX_EPOCH \\\n",
        "  --log-interval 100 \\\n",
        "\n",
        "# --memory-efficient-fp16 instead of --fp16 solves 'CUDA out of memory' problem, but slow training\n",
        "# --max-sentences $MAX_SENTENCES , not batch-size\n",
        "# --fp16-scale-window 128 default"
      ],
      "metadata": {
        "id": "8gGKlopBdNYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7a4998-e4f5-4afa-ea63-c468eb544c6b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: fairseq-train: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "start = timer()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "end = timer()\n",
        "print(\"%4f seconds, %4f minutes elapsed\" % (float(end-start), float((end-start)/60)))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8185c9ee39774fcba9200e83819fce3f",
        "source_hash": "c4a351e7",
        "execution_start": 1674080563381,
        "execution_millis": 17834,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "8NO7NW3bZIqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8480e465-3e56-4052-ddb3-2d069b0c1add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 18376\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4594\n",
            "  Number of trainable parameters = 109483778\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230126_053114-z8cfj2w4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ojw92/huggingface/runs/z8cfj2w4\" target=\"_blank\">glowing-peony-7</a></strong> to <a href=\"https://wandb.ai/ojw92/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/ojw92/huggingface\" target=\"_blank\">https://wandb.ai/ojw92/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/ojw92/huggingface/runs/z8cfj2w4\" target=\"_blank\">https://wandb.ai/ojw92/huggingface/runs/z8cfj2w4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4594' max='4594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4594/4594 58:07, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.396000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.318200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.290100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.261400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.219600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.224400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.209400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-1000\n",
            "Configuration saved in output/checkpoint-1000/config.json\n",
            "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-1500\n",
            "Configuration saved in output/checkpoint-1500/config.json\n",
            "Model weights saved in output/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-2000\n",
            "Configuration saved in output/checkpoint-2000/config.json\n",
            "Model weights saved in output/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-2500\n",
            "Configuration saved in output/checkpoint-2500/config.json\n",
            "Model weights saved in output/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-3000\n",
            "Configuration saved in output/checkpoint-3000/config.json\n",
            "Model weights saved in output/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-3500\n",
            "Configuration saved in output/checkpoint-3500/config.json\n",
            "Model weights saved in output/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-4000\n",
            "Configuration saved in output/checkpoint-4000/config.json\n",
            "Model weights saved in output/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to output/checkpoint-4500\n",
            "Configuration saved in output/checkpoint-4500/config.json\n",
            "Model weights saved in output/checkpoint-4500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
            "Saving model checkpoint to /tmp/tmp6u8e3ebk\n",
            "Configuration saved in /tmp/tmp6u8e3ebk/config.json\n",
            "Model weights saved in /tmp/tmp6u8e3ebk/pytorch_model.bin\n",
            "Logging model artifacts. ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3491.230337 seconds, 58.187172 minutes elapsed\n"
          ]
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "97a062b8225e4125971486d915e3ac86",
        "deepnote_cell_type": "code",
        "id": "4L3oPcUvZIqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "03e93417-6741-487b-c1a9-e4b016d9dfc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 4594\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/575 02:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.trainer_utils.EvalPrediction'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3668666183948517,\n",
              " 'eval_accuracy': 0.8976926425772747,\n",
              " 'eval_precision': 0.757168458781362,\n",
              " 'eval_recall': 0.8093869731800766,\n",
              " 'eval_f1': 0.7824074074074074,\n",
              " 'eval_runtime': 151.205,\n",
              " 'eval_samples_per_second': 30.383,\n",
              " 'eval_steps_per_second': 3.803,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "2920442657d045288b468403b8e7ce45",
        "deepnote_cell_type": "code",
        "id": "ee-3alVdZIqk"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Super charging is working very well.\"\n",
        "# text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "print(outputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)    # also gelu(), silu()\n",
        "print(predictions)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "b95d7749d3074a20bdfa3cdc432b149e",
        "deepnote_cell_type": "code",
        "id": "Ndgwa_feZIql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb622939-31d2-4012-ecfc-2575566ea1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 3.4762, -3.3150]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9988777 , 0.00112227]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('BertPractice')"
      ],
      "metadata": {
        "id": "ehJCv_jKWoge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f929b6-9be7-4450-d64a-aee6ab4a6ba5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to BertPractice\n",
            "Configuration saved in BertPractice/config.json\n",
            "Model weights saved in BertPractice/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.save_model('/content/drive/MyDrive/Youtube Tutorials/toxic')\n",
        "# model_2 = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Youtube Tutorials/toxic\")\n",
        "# model_2.to('cuda')"
      ],
      "metadata": {
        "id": "FDIfAtXeWqBP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = BertForSequenceClassification.from_pretrained('BertPractice')\n",
        "model_2.to('cuda')"
      ],
      "metadata": {
        "id": "9af__siKWrvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c535a602-4151-4a08-9c63-64511f8541ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file BertPractice/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.27.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file BertPractice/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BertPractice.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Super charging is working very well.\"\n",
        "text = \"so many issues with this phone.\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model_2(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "53e74eee144d445da85927276d7daff3",
        "deepnote_cell_type": "code",
        "id": "Nf4WU--hZIql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ddbbce-1ab5-479d-b1dc-21e8e1b4cd9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04695127, 0.9530487 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on daily data\n",
        "\n",
        "def pred_day(voctoday):\n",
        "  voclist = list(voctoday['Text'])\n",
        "  predlist = []\n",
        "\n",
        "  for i in range(len(voclist)):\n",
        "    inputs = tokenizer(voclist[i], padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "    outputs = model_2(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predictions = predictions.cpu().detach().numpy()\n",
        "    predlist.append(predictions)\n",
        "\n",
        "  organizedzip = zip([x[:25] for x in voclist],\n",
        "                    predlist,\n",
        "                    voctoday['Class'])\n",
        "  \n",
        "  # results as voc text, predictions, and actual value\n",
        "  vocresult = pd.DataFrame(list(organizedzip), columns=['Text','Prediction','Actual'])\n",
        "\n",
        "  return vocresult\n"
      ],
      "metadata": {
        "id": "MC4gHsQTbo_o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test VOC\n",
        "# import file and combine title & content\n",
        "\n",
        "#voc0123 = pd.read_csv('/20230123_test.csv', index_col=0).drop_duplicates()\n",
        "#voc0123 = data_concat(voc0123.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc0124 = pd.read_csv('/20230124_test.csv', index_col=0).drop_duplicates()\n",
        "voc0124 = data_concat(voc0124.loc[: , 'Title':'Class'])\n",
        "\n",
        "voc0125 = pd.read_csv('/20230125_test.csv', index_col=0).drop_duplicates()\n",
        "voc0125 = data_concat(voc0125.loc[: , 'Title':'Class'])\n",
        "\n",
        "\n",
        "#vocresult0123 = pred_day(voc0123)\n",
        "#vocresult0123"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6093bde4694f46c195c95d0798e529cb",
        "deepnote_cell_type": "code",
        "id": "IvNon4aUZIql"
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult0124 = pred_day(voc0124)\n",
        "vocresult0124"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8207dc085d8b42718086312e08437452",
        "deepnote_cell_type": "code",
        "id": "5Bw4LKQzZIqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbcde4be-e265-4a38-d9aa-da5d53183a23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Text                     Prediction  Actual\n",
              "0   Switch from Fold2, feel l    [[0.98977965, 0.010220389]]       1\n",
              "1   How did you buy / get you  [[0.99949646, 0.00050346897]]       0\n",
              "2   Music volume issue? When      [[0.026815688, 0.9731843]]       1\n",
              "3   Sometimes 3 random lines     [[0.027537638, 0.97246236]]       1\n",
              "4   Difference between adapti   [[0.9994636, 0.00053636456]]       0\n",
              "5   Adjust default camera bri   [[0.99626154, 0.0037384112]]       1\n",
              "6   Attention Galaxy users, u     [[0.999458, 0.0005419959]]       0\n",
              "7   Notifications not vibrati     [[0.02895688, 0.97104305]]       1\n",
              "8   Bluetooth Phone Issues [S     [[0.028390499, 0.9716095]]       1\n",
              "9   What are the first things  [[0.99943095, 0.00056907715]]       0\n",
              "10  Take a note during a call   [[0.99946886, 0.0005311911]]       0\n",
              "11  Anyone else's device been    [[0.026300363, 0.97369957]]       1\n",
              "12  Galaxy A52 too S22U Camer   [[0.9994791, 0.00052096276]]       0\n",
              "13  Shutter lag What shutter        [[0.0319731, 0.9680269]]       0\n",
              "14  Find My Mobile not updati   [[0.99577576, 0.0042242035]]       0\n",
              "15  one-handed mode shenaniga     [[0.999263, 0.0007369962]]       0\n",
              "16  Issues while using wifi 6    [[0.026675116, 0.97332484]]       1\n",
              "17  I don't think it's suppos     [[0.9836939, 0.016306126]]       0\n",
              "18  Heat issue. , noob questi      [[0.32884163, 0.6711583]]       1\n",
              "19  Battery Charge Hello, is      [[0.9963212, 0.003678783]]       0\n",
              "20  Is there any way that i c  [[0.99951315, 0.00048680915]]       0\n",
              "21  Does the Edge Panel cause    [[0.9868771, 0.0131229265]]       0\n",
              "22  No notification sounds wh    [[0.9992681, 0.0007318946]]       0\n",
              "23  Should I buy the S22+? I     [[0.9995443, 0.0004556424]]       0\n",
              "24  Was the Ultra worth it? I      [[0.9994362, 0.00056376]]       0\n",
              "25  US S22 Ultra getting 2nd     [[0.9994573, 0.0005427496]]       0\n",
              "26  I just got my s22 and it       [[0.05202943, 0.9479706]]       1\n",
              "27  S22+ Charging Port Issue      [[0.028565401, 0.9714346]]       1\n",
              "28  S22+ Google Assistant sto    [[0.030893907, 0.96910614]]       1\n",
              "29  Charging issue I got the      [[0.026685296, 0.9733147]]       1\n",
              "30  How to reduce heat from p     [[0.9803525, 0.019647518]]       1\n",
              "31  Samsung ROM via Odin Hey     [[0.9994301, 0.0005699076]]       0\n",
              "32  Bluetooth notification so    [[0.028902665, 0.97109735]]       1\n",
              "33  My latest setup. Bluetoot   [[0.99927825, 0.0007217285]]       0\n",
              "34  5G Standalone is official    [[0.9967353, 0.0032646647]]       0\n",
              "35  Motion Photo keeps turnin   [[0.99902284, 0.0009771334]]       0\n",
              "36  Check your charger error      [[0.035083655, 0.9649163]]       1\n",
              "37  Is there a way to undo un   [[0.99922276, 0.0007772582]]       0\n",
              "38  Help help moving audio fi     [[0.999073, 0.0009269999]]       0\n",
              "39  Unable to receive any ser     [[0.028548475, 0.9714515]]       1\n",
              "40  Samsung Wallet Someone Pl  [[0.99925214, 0.00074788614]]       0\n",
              "41  My last samsung s22 ultra    [[0.99732447, 0.002675496]]       1\n",
              "42  S22 Ultra Voicemail Probl       [[0.03166602, 0.968334]]       1\n",
              "43  Wifi issues with S22 Ultr      [[0.03573383, 0.9642661]]       1\n",
              "44  Phone problems with s22 u      [[0.37028036, 0.6297197]]       1\n",
              "45  S22Ultra The camera featu    [[0.030991089, 0.96900886]]       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a612b7c2-45e1-4631-9c64-3b788c86236b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switch from Fold2, feel l</td>\n",
              "      <td>[[0.98977965, 0.010220389]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How did you buy / get you</td>\n",
              "      <td>[[0.99949646, 0.00050346897]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Music volume issue? When</td>\n",
              "      <td>[[0.026815688, 0.9731843]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sometimes 3 random lines</td>\n",
              "      <td>[[0.027537638, 0.97246236]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Difference between adapti</td>\n",
              "      <td>[[0.9994636, 0.00053636456]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adjust default camera bri</td>\n",
              "      <td>[[0.99626154, 0.0037384112]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Attention Galaxy users, u</td>\n",
              "      <td>[[0.999458, 0.0005419959]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Notifications not vibrati</td>\n",
              "      <td>[[0.02895688, 0.97104305]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bluetooth Phone Issues [S</td>\n",
              "      <td>[[0.028390499, 0.9716095]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What are the first things</td>\n",
              "      <td>[[0.99943095, 0.00056907715]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Take a note during a call</td>\n",
              "      <td>[[0.99946886, 0.0005311911]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Anyone else's device been</td>\n",
              "      <td>[[0.026300363, 0.97369957]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Galaxy A52 too S22U Camer</td>\n",
              "      <td>[[0.9994791, 0.00052096276]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shutter lag What shutter</td>\n",
              "      <td>[[0.0319731, 0.9680269]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Find My Mobile not updati</td>\n",
              "      <td>[[0.99577576, 0.0042242035]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>one-handed mode shenaniga</td>\n",
              "      <td>[[0.999263, 0.0007369962]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Issues while using wifi 6</td>\n",
              "      <td>[[0.026675116, 0.97332484]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I don't think it's suppos</td>\n",
              "      <td>[[0.9836939, 0.016306126]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Heat issue. , noob questi</td>\n",
              "      <td>[[0.32884163, 0.6711583]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Battery Charge Hello, is</td>\n",
              "      <td>[[0.9963212, 0.003678783]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Is there any way that i c</td>\n",
              "      <td>[[0.99951315, 0.00048680915]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Does the Edge Panel cause</td>\n",
              "      <td>[[0.9868771, 0.0131229265]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>No notification sounds wh</td>\n",
              "      <td>[[0.9992681, 0.0007318946]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Should I buy the S22+? I</td>\n",
              "      <td>[[0.9995443, 0.0004556424]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Was the Ultra worth it? I</td>\n",
              "      <td>[[0.9994362, 0.00056376]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>US S22 Ultra getting 2nd</td>\n",
              "      <td>[[0.9994573, 0.0005427496]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>I just got my s22 and it</td>\n",
              "      <td>[[0.05202943, 0.9479706]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>S22+ Charging Port Issue</td>\n",
              "      <td>[[0.028565401, 0.9714346]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>S22+ Google Assistant sto</td>\n",
              "      <td>[[0.030893907, 0.96910614]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Charging issue I got the</td>\n",
              "      <td>[[0.026685296, 0.9733147]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>How to reduce heat from p</td>\n",
              "      <td>[[0.9803525, 0.019647518]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Samsung ROM via Odin Hey</td>\n",
              "      <td>[[0.9994301, 0.0005699076]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Bluetooth notification so</td>\n",
              "      <td>[[0.028902665, 0.97109735]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>My latest setup. Bluetoot</td>\n",
              "      <td>[[0.99927825, 0.0007217285]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>5G Standalone is official</td>\n",
              "      <td>[[0.9967353, 0.0032646647]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Motion Photo keeps turnin</td>\n",
              "      <td>[[0.99902284, 0.0009771334]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Check your charger error</td>\n",
              "      <td>[[0.035083655, 0.9649163]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Is there a way to undo un</td>\n",
              "      <td>[[0.99922276, 0.0007772582]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Help help moving audio fi</td>\n",
              "      <td>[[0.999073, 0.0009269999]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Unable to receive any ser</td>\n",
              "      <td>[[0.028548475, 0.9714515]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Samsung Wallet Someone Pl</td>\n",
              "      <td>[[0.99925214, 0.00074788614]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>My last samsung s22 ultra</td>\n",
              "      <td>[[0.99732447, 0.002675496]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>S22 Ultra Voicemail Probl</td>\n",
              "      <td>[[0.03166602, 0.968334]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Wifi issues with S22 Ultr</td>\n",
              "      <td>[[0.03573383, 0.9642661]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Phone problems with s22 u</td>\n",
              "      <td>[[0.37028036, 0.6297197]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>S22Ultra The camera featu</td>\n",
              "      <td>[[0.030991089, 0.96900886]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a612b7c2-45e1-4631-9c64-3b788c86236b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a612b7c2-45e1-4631-9c64-3b788c86236b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a612b7c2-45e1-4631-9c64-3b788c86236b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": [
        "vocresult0125 = pred_day(voc0125)\n",
        "vocresult0125"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "5aeac4c1c9b34e4b9afe24f40e1d3c27",
        "source_hash": "24acd7c3",
        "is_code_hidden": true,
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "XHyZQQDLZIqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a4d9c3e-d11b-421e-ab05-1bce1bfb42ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Text                     Prediction  Actual\n",
              "0   S22U trouble with Google     [[0.025229042, 0.97477096]]       1\n",
              "1   Minimize - maximize requi      [[0.12816726, 0.8718327]]       1\n",
              "2   Trade in values from 2022    [[0.9994573, 0.0005426681]]       0\n",
              "3   Anyone has any idea how t   [[0.99900526, 0.0009947564]]       0\n",
              "4   S908U1UES2BWA2 Update and   [[0.99888545, 0.0011145528]]       0\n",
              "5   Case for Power Share? Are   [[0.99946326, 0.0005367809]]       0\n",
              "6   apps going to sleep didn'     [[0.034483686, 0.9655164]]       1\n",
              "7   45w small charger for the    [[0.9994886, 0.0005114392]]       0\n",
              "8   Plastic film that came wi    [[0.9993598, 0.0006402123]]       0\n",
              "9   Not able to make calls wh    [[0.033993553, 0.96600646]]       0\n",
              "10  Just saw a video about di  [[0.99910337, 0.00089659286]]       0\n",
              "11  Has anyone else's pin to      [[0.9750019, 0.024998108]]       0\n",
              "12  Adaptive mode stuck at 10    [[0.9992912, 0.0007087586]]       0\n",
              "13  Coming from Iphone. What   [[0.99952114, 0.00047887984]]       0\n",
              "14  rectangle around the fing   [[0.9993048, 0.00069521257]]       0\n",
              "15  Dialer Background Is ther    [[0.9994622, 0.0005378154]]       0\n",
              "16  Update for my s22 u Turns     [[0.9993949, 0.000605104]]       0\n",
              "17  Not able to make calls wh    [[0.028578734, 0.97142124]]       1\n",
              "18  Samsung to Samsung transf   [[0.9992181, 0.00078181934]]       0\n",
              "19  Why Is My Front Facing Vi    [[0.035547912, 0.96445215]]       1\n",
              "20  Is there a way to make th    [[0.999433, 0.00056702085]]       1\n",
              "21  Are these toggles disable    [[0.9994856, 0.0005143554]]       0\n",
              "22  Should I upgrade to S23U    [[0.9995396, 0.00046040156]]       0\n",
              "23  S23 Ultra, yes please. So   [[0.99939513, 0.0006049111]]       0\n",
              "24  PSA with this latest upda      [[0.7546573, 0.24534264]]       1\n",
              "25  Adaptive Refresh Rate Hel     [[0.999438, 0.0005620314]]       0\n",
              "26  New Processor = Better Th     [[0.9597636, 0.040236425]]       0\n",
              "27  Any regrets going from S2   [[0.99948406, 0.0005158763]]       0\n",
              "28  upgrading my base s22 I'v     [[0.999387, 0.0006129024]]       0\n",
              "29  Congratulations Samsung!!     [[0.9994955, 0.000504503]]       0\n",
              "30  Warranty question I'm goi  [[0.99944013, 0.00055979844]]       0\n",
              "31  S22 Ultra to Z fold 4 to    [[0.9995363, 0.00046375176]]       0\n",
              "32  trade in question for gal   [[0.99946135, 0.0005386131]]       0\n",
              "33  Do you think it will be w    [[0.9994727, 0.0005273849]]       0\n",
              "34  S9 upgrade to S21 or S 21  [[0.99948907, 0.00051085406]]       0\n",
              "35  s22 ultra value What do y    [[0.9994553, 0.0005446922]]       0\n",
              "36  Just bought an S22 256 gb   [[0.99948573, 0.0005142206]]       0\n",
              "37  Need to customize group r    [[0.9993326, 0.0006673758]]       1\n",
              "38  Android/ OneUI Feature Re    [[0.99950826, 0.000491784]]       0\n",
              "39  I've got a great suggesti   [[0.99950254, 0.0004974154]]       0\n",
              "40  Text messages Is there a    [[0.99941003, 0.0005899255]]       0\n",
              "41  Deactivate VM on Galaxy 2    [[0.9995228, 0.0004771804]]       0\n",
              "42  Emails Does anybody know      [[0.58020884, 0.41979113]]       1\n",
              "43  Carpeta Segura No puedo a    [[0.9994174, 0.0005826212]]       0\n",
              "44  Phone is listening to me      [[0.9795447, 0.020455306]]       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ebb135e-42ff-498a-9575-a9d0fd4f420b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S22U trouble with Google</td>\n",
              "      <td>[[0.025229042, 0.97477096]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Minimize - maximize requi</td>\n",
              "      <td>[[0.12816726, 0.8718327]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trade in values from 2022</td>\n",
              "      <td>[[0.9994573, 0.0005426681]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Anyone has any idea how t</td>\n",
              "      <td>[[0.99900526, 0.0009947564]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S908U1UES2BWA2 Update and</td>\n",
              "      <td>[[0.99888545, 0.0011145528]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Case for Power Share? Are</td>\n",
              "      <td>[[0.99946326, 0.0005367809]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>apps going to sleep didn'</td>\n",
              "      <td>[[0.034483686, 0.9655164]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>45w small charger for the</td>\n",
              "      <td>[[0.9994886, 0.0005114392]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Plastic film that came wi</td>\n",
              "      <td>[[0.9993598, 0.0006402123]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Not able to make calls wh</td>\n",
              "      <td>[[0.033993553, 0.96600646]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Just saw a video about di</td>\n",
              "      <td>[[0.99910337, 0.00089659286]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Has anyone else's pin to</td>\n",
              "      <td>[[0.9750019, 0.024998108]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Adaptive mode stuck at 10</td>\n",
              "      <td>[[0.9992912, 0.0007087586]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Coming from Iphone. What</td>\n",
              "      <td>[[0.99952114, 0.00047887984]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>rectangle around the fing</td>\n",
              "      <td>[[0.9993048, 0.00069521257]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Dialer Background Is ther</td>\n",
              "      <td>[[0.9994622, 0.0005378154]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Update for my s22 u Turns</td>\n",
              "      <td>[[0.9993949, 0.000605104]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Not able to make calls wh</td>\n",
              "      <td>[[0.028578734, 0.97142124]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Samsung to Samsung transf</td>\n",
              "      <td>[[0.9992181, 0.00078181934]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Why Is My Front Facing Vi</td>\n",
              "      <td>[[0.035547912, 0.96445215]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Is there a way to make th</td>\n",
              "      <td>[[0.999433, 0.00056702085]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Are these toggles disable</td>\n",
              "      <td>[[0.9994856, 0.0005143554]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Should I upgrade to S23U</td>\n",
              "      <td>[[0.9995396, 0.00046040156]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>S23 Ultra, yes please. So</td>\n",
              "      <td>[[0.99939513, 0.0006049111]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>PSA with this latest upda</td>\n",
              "      <td>[[0.7546573, 0.24534264]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Adaptive Refresh Rate Hel</td>\n",
              "      <td>[[0.999438, 0.0005620314]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>New Processor = Better Th</td>\n",
              "      <td>[[0.9597636, 0.040236425]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Any regrets going from S2</td>\n",
              "      <td>[[0.99948406, 0.0005158763]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>upgrading my base s22 I'v</td>\n",
              "      <td>[[0.999387, 0.0006129024]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Congratulations Samsung!!</td>\n",
              "      <td>[[0.9994955, 0.000504503]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Warranty question I'm goi</td>\n",
              "      <td>[[0.99944013, 0.00055979844]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>S22 Ultra to Z fold 4 to</td>\n",
              "      <td>[[0.9995363, 0.00046375176]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>trade in question for gal</td>\n",
              "      <td>[[0.99946135, 0.0005386131]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Do you think it will be w</td>\n",
              "      <td>[[0.9994727, 0.0005273849]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>S9 upgrade to S21 or S 21</td>\n",
              "      <td>[[0.99948907, 0.00051085406]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>s22 ultra value What do y</td>\n",
              "      <td>[[0.9994553, 0.0005446922]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Just bought an S22 256 gb</td>\n",
              "      <td>[[0.99948573, 0.0005142206]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Need to customize group r</td>\n",
              "      <td>[[0.9993326, 0.0006673758]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Android/ OneUI Feature Re</td>\n",
              "      <td>[[0.99950826, 0.000491784]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>I've got a great suggesti</td>\n",
              "      <td>[[0.99950254, 0.0004974154]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Text messages Is there a</td>\n",
              "      <td>[[0.99941003, 0.0005899255]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Deactivate VM on Galaxy 2</td>\n",
              "      <td>[[0.9995228, 0.0004771804]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Emails Does anybody know</td>\n",
              "      <td>[[0.58020884, 0.41979113]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Carpeta Segura No puedo a</td>\n",
              "      <td>[[0.9994174, 0.0005826212]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Phone is listening to me</td>\n",
              "      <td>[[0.9795447, 0.020455306]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ebb135e-42ff-498a-9575-a9d0fd4f420b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ebb135e-42ff-498a-9575-a9d0fd4f420b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ebb135e-42ff-498a-9575-a9d0fd4f420b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "501fe0946abe4e6398eb6a364a652e3c",
        "source_hash": "b623e53d",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "id": "HOzIXC_iZIqm"
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e5caba9f-cd36-4d50-aaa3-2cf59957a2f4' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "llB-FWxEZIqn"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {},
    "orig_nbformat": 2,
    "deepnote_notebook_id": "99baf882d48d4fa4b40b67d8bd9057bf",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}